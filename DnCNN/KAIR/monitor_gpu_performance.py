#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GPUæ€§èƒ½ç›£æ§è…³æœ¬
å¯¦æ™‚ç›£æ§è¨“ç·´éç¨‹ä¸­çš„GPUåˆ©ç”¨ç‡å’Œè¨˜æ†¶é«”ä½¿ç”¨
"""

import time
import subprocess
import psutil
import torch
import matplotlib.pyplot as plt
from datetime import datetime
import json
import os
import matplotlib.font_manager as fm

class GPUMonitor:
    def __init__(self, log_interval=10):
        self.log_interval = log_interval
        self.gpu_usage_history = []
        self.memory_usage_history = []
        self.timestamps = []
        self.monitoring = False
        
    def get_gpu_info(self):
        """ç²å–GPUä½¿ç”¨æƒ…æ³"""
        try:
            # ä½¿ç”¨nvidia-smiç²å–GPUä¿¡æ¯
            result = subprocess.run([
                'nvidia-smi', 
                '--query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu',
                '--format=csv,noheader,nounits'
            ], capture_output=True, text=True)
            
            if result.returncode == 0:
                values = result.stdout.strip().split(', ')
                return {
                    'gpu_utilization': float(values[0]),
                    'memory_used_mb': float(values[1]),
                    'memory_total_mb': float(values[2]),
                    'temperature': float(values[3])
                }
        except Exception as e:
            print(f"ç²å–GPUä¿¡æ¯å¤±æ•—: {e}")
            
        # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨PyTorch
        if torch.cuda.is_available():
            return {
                'gpu_utilization': 0,  # PyTorchç„¡æ³•ç›´æ¥ç²å–åˆ©ç”¨ç‡
                'memory_used_mb': torch.cuda.memory_allocated() / 1024**2,
                'memory_total_mb': torch.cuda.get_device_properties(0).total_memory / 1024**2,
                'temperature': 0
            }
        
        return None
    
    def get_system_info(self):
        """ç²å–ç³»çµ±ä¿¡æ¯"""
        return {
            'cpu_percent': psutil.cpu_percent(),
            'memory_percent': psutil.virtual_memory().percent,
            'disk_io': psutil.disk_io_counters()._asdict() if psutil.disk_io_counters() else {}
        }
    
    def log_performance(self):
        """è¨˜éŒ„æ€§èƒ½æ•¸æ“š"""
        gpu_info = self.get_gpu_info()
        system_info = self.get_system_info()
        
        if gpu_info:
            timestamp = datetime.now()
            self.timestamps.append(timestamp)
            self.gpu_usage_history.append(gpu_info['gpu_utilization'])
            self.memory_usage_history.append(gpu_info['memory_used_mb'] / gpu_info['memory_total_mb'] * 100)
            
            # å¯¦æ™‚è¼¸å‡º
            print(f"[{timestamp.strftime('%H:%M:%S')}] "
                  f"GPU: {gpu_info['gpu_utilization']:5.1f}% | "
                  f"VRAM: {gpu_info['memory_used_mb']/1024:.1f}GB/"
                  f"{gpu_info['memory_total_mb']/1024:.1f}GB "
                  f"({gpu_info['memory_used_mb']/gpu_info['memory_total_mb']*100:.1f}%) | "
                  f"Temp: {gpu_info['temperature']}Â°C | "
                  f"CPU: {system_info['cpu_percent']:5.1f}% | "
                  f"RAM: {system_info['memory_percent']:5.1f}%")
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            log_data = {
                'timestamp': timestamp.isoformat(),
                'gpu': gpu_info,
                'system': system_info
            }
            
            with open('gpu_performance.log', 'a') as f:
                f.write(json.dumps(log_data) + '\n')
    
    def start_monitoring(self):
        """é–‹å§‹ç›£æ§"""
        self.monitoring = True
        print("ğŸš€ é–‹å§‹GPUæ€§èƒ½ç›£æ§...")
        print("=" * 80)
        
        try:
            while self.monitoring:
                self.log_performance()
                time.sleep(self.log_interval)
        except KeyboardInterrupt:
            print("\nâ¹ï¸  ç›£æ§å·²åœæ­¢")
            self.stop_monitoring()
    
    def stop_monitoring(self):
        """åœæ­¢ç›£æ§"""
        self.monitoring = False
        self.generate_report()
    
    def generate_report(self):
        """ç”Ÿæˆæ€§èƒ½å ±å‘Š"""
        if not self.gpu_usage_history:
            print("æ²’æœ‰æ€§èƒ½æ•¸æ“šå¯ç”Ÿæˆå ±å‘Š")
            return
        
        # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
        avg_gpu_usage = sum(self.gpu_usage_history) / len(self.gpu_usage_history)
        max_gpu_usage = max(self.gpu_usage_history)
        avg_memory_usage = sum(self.memory_usage_history) / len(self.memory_usage_history)
        max_memory_usage = max(self.memory_usage_history)
        
        print("\nğŸ“Š æ€§èƒ½çµ±è¨ˆå ±å‘Š:")
        print("=" * 50)
        print(f"ç›£æ§æ™‚é•·: {len(self.gpu_usage_history) * self.log_interval / 60:.1f} åˆ†é˜")
        print(f"å¹³å‡GPUåˆ©ç”¨ç‡: {avg_gpu_usage:.1f}%")
        print(f"æœ€é«˜GPUåˆ©ç”¨ç‡: {max_gpu_usage:.1f}%")
        print(f"å¹³å‡è¨˜æ†¶é«”ä½¿ç”¨: {avg_memory_usage:.1f}%")
        print(f"æœ€é«˜è¨˜æ†¶é«”ä½¿ç”¨: {max_memory_usage:.1f}%")
        
        # ç”Ÿæˆåœ–è¡¨
        self.plot_performance()
        
        # å„ªåŒ–å»ºè­°
        self.provide_recommendations(avg_gpu_usage, max_gpu_usage, avg_memory_usage)
    
    def plot_performance(self):
        """ç¹ªè£½æ€§èƒ½åœ–è¡¨"""
        if not self.gpu_usage_history:
            return
        
        # è¨­å®šä¸­æ–‡å­—é«”
        font_path = r'C:\Users\brogent\Desktop\Image_Noise\Mamelon.otf'
        if os.path.exists(font_path):
            chinese_font = fm.FontProperties(fname=font_path)
            plt.rcParams['font.family'] = 'sans-serif'
            plt.rcParams['axes.unicode_minus'] = False
        else:
            chinese_font = None
            print(f"è­¦å‘Š: æ‰¾ä¸åˆ°å­—é«”æª”æ¡ˆ {font_path}")
        
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
        
        # GPUåˆ©ç”¨ç‡åœ–
        ax1.plot(self.gpu_usage_history, 'b-', linewidth=2, label='GPUåˆ©ç”¨ç‡')
        ax1.set_ylabel('GPUåˆ©ç”¨ç‡ (%)', fontproperties=chinese_font)
        ax1.set_title('GPUæ€§èƒ½ç›£æ§', fontproperties=chinese_font)
        ax1.grid(True, alpha=0.3)
        if chinese_font:
            ax1.legend(prop=chinese_font)
        else:
            ax1.legend()
        ax1.set_ylim(0, 100)
        
        # è¨˜æ†¶é«”ä½¿ç”¨åœ–
        ax2.plot(self.memory_usage_history, 'r-', linewidth=2, label='è¨˜æ†¶é«”ä½¿ç”¨')
        ax2.set_ylabel('è¨˜æ†¶é«”ä½¿ç”¨ (%)', fontproperties=chinese_font)
        ax2.set_xlabel('æ™‚é–“é»', fontproperties=chinese_font)
        ax2.grid(True, alpha=0.3)
        if chinese_font:
            ax2.legend(prop=chinese_font)
        else:
            ax2.legend()
        ax2.set_ylim(0, 100)
        
        # è¨­å®šåˆ»åº¦æ¨™ç±¤å­—é«”
        if chinese_font:
            for label in ax1.get_xticklabels() + ax1.get_yticklabels():
                label.set_fontproperties(chinese_font)
            for label in ax2.get_xticklabels() + ax2.get_yticklabels():
                label.set_fontproperties(chinese_font)
        
        plt.tight_layout()
        plt.savefig('gpu_performance_report.png', dpi=300, bbox_inches='tight')
        print("ğŸ“ˆ æ€§èƒ½åœ–è¡¨å·²ä¿å­˜è‡³: gpu_performance_report.png")
    
    def provide_recommendations(self, avg_gpu, max_gpu, avg_memory):
        """æä¾›å„ªåŒ–å»ºè­°"""
        print("\nğŸ’¡ å„ªåŒ–å»ºè­°:")
        print("=" * 50)
        
        if avg_gpu < 70:
            print("ğŸ”¸ GPUåˆ©ç”¨ç‡åä½ï¼Œå»ºè­°:")
            print("   - å¢åŠ æ‰¹æ¬¡å¤§å° (batch_size)")
            print("   - æ¸›å°‘æ•¸æ“šè¼‰å…¥å·¥ä½œç·šç¨‹æ•¸ (num_workers)")
            print("   - æª¢æŸ¥æ˜¯å¦æœ‰CPUç“¶é ¸")
        
        if max_gpu > 95:
            print("ğŸ”¸ GPUåˆ©ç”¨ç‡éé«˜ï¼Œå¯èƒ½å‡ºç¾ç“¶é ¸:")
            print("   - è€ƒæ…®é™ä½æ‰¹æ¬¡å¤§å°")
            print("   - å•Ÿç”¨æ··åˆç²¾åº¦è¨“ç·´ (AMP)")
        
        if avg_memory > 85:
            print("ğŸ”¸ è¨˜æ†¶é«”ä½¿ç”¨ç‡é«˜ï¼Œå»ºè­°:")
            print("   - é™ä½æ‰¹æ¬¡å¤§å°")
            print("   - å•Ÿç”¨æ··åˆç²¾åº¦è¨“ç·´")
            print("   - å¢åŠ è¨˜æ†¶é«”æ¸…ç†é »ç‡")
        
        if avg_gpu > 80 and avg_memory < 60:
            print("âœ… GPUé…ç½®è‰¯å¥½ï¼Œåˆ©ç”¨ç‡é«˜ä¸”è¨˜æ†¶é«”å……è¶³")

def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='GPUæ€§èƒ½ç›£æ§å·¥å…·')
    parser.add_argument('--interval', type=int, default=10, help='ç›£æ§é–“éš”(ç§’)')
    parser.add_argument('--duration', type=int, default=0, help='ç›£æ§æ™‚é•·(ç§’)ï¼Œ0è¡¨ç¤ºæŒçºŒç›£æ§')
    
    args = parser.parse_args()
    
    monitor = GPUMonitor(log_interval=args.interval)
    
    if args.duration > 0:
        print(f"å°‡ç›£æ§ {args.duration} ç§’...")
        import threading
        timer = threading.Timer(args.duration, monitor.stop_monitoring)
        timer.start()
    
    try:
        monitor.start_monitoring()
    except KeyboardInterrupt:
        print("\nç”¨æˆ¶ä¸­æ–·ç›£æ§")
        monitor.stop_monitoring()

if __name__ == "__main__":
    main()
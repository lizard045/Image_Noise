#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import argparse
import logging
import torch
import numpy as np
from collections import OrderedDict
import cv2
import time
from torch.cuda.amp import autocast, GradScaler
import torch.backends.cudnn as cudnn

from utils import utils_logger
from utils import utils_image as util
from models.network_unet import UNetRes
import models.network_unet as nunet
import torch.nn as nn
"""
å°åŒ—101å½±åƒå»å™ªè…³æœ¬ - å…¨é¢å¢å¼·ç‰ˆ
ä½¿ç”¨DRUNetæ¨¡å‹é€²è¡Œå½©è‰²å½±åƒå»å™ªè™•ç†

ğŸš€ æ–°å¢åŠŸèƒ½ï¼š
- è‡ªé©æ‡‰åƒæ•¸ç³»çµ±ï¼šæ ¹æ“šå½±åƒè¤‡é›œåº¦èª¿æ•´é›™æµåƒæ•¸
- å•Ÿç”¨é«˜ç´šåŠŸèƒ½ï¼šé€²éšé›™æµèåˆ + å°æ³¢æ®˜å·®è£œå„Ÿ + é »åŸŸç´°ç¯€ä¿è­·
- åƒæ•¸èª¿å„ªï¼šæ‰€æœ‰è™•ç†åƒæ•¸éƒ½ç¶“éå„ªåŒ–ï¼Œæå‡ç´°ç¯€ä¿ç•™æ•ˆæœ

ä½¿ç”¨æ–¹æ³•:
python taipei101_denoise.py --input_dir testsets/" " --output_dir " "

"""
print("å¯¦éš›åŒ¯å…¥æª”æ¡ˆï¼š", nunet.__file__)
print("UNetRes åƒæ•¸ï¼š", nunet.UNetRes.__init__.__code__.co_varnames)

class GPUOptimizer:
    """GPUå„ªåŒ–ç®¡ç†å™¨"""
    
    def __init__(self):
        self.device = None
        self.gpu_info = {}
        self.use_amp = False
        self.scaler = None
        
    def setup_gpu(self):
        """è¨­ç½®GPUå„ªåŒ–é…ç½®"""
        if torch.cuda.is_available():
            self.device = torch.device('cuda')
            # å•Ÿç”¨cuDNNåŸºæº–æ¸¬è©¦æ¨¡å¼
            cudnn.benchmark = True
            cudnn.deterministic = False
            
            # GPUè¨˜æ†¶é«”ç®¡ç†
            torch.cuda.empty_cache()
            os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
            
            # ç²å–GPUè³‡è¨Š
            self.gpu_info = {
                'name': torch.cuda.get_device_name(0),
                'memory_total': torch.cuda.get_device_properties(0).total_memory / 1024**3,
                'memory_available': (torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()) / 1024**3
            }
            
            # æ ¹æ“šGPUè¨˜æ†¶é«”æ±ºå®šæ˜¯å¦ä½¿ç”¨AMP
            if self.gpu_info['memory_total'] >= 4.0:  # 4GBä»¥ä¸Šä½¿ç”¨AMP
                self.use_amp = True
                try:
                    # æ–°ç‰ˆPyTorchèªæ³•
                    from torch.amp import GradScaler
                    self.scaler = GradScaler('cuda')
                except ImportError:
                    # èˆŠç‰ˆPyTorchèªæ³•
                    from torch.cuda.amp import GradScaler
                    self.scaler = GradScaler()
                
            print(f" GPUå„ªåŒ–å•Ÿç”¨:")
            print(f"   è¨­å‚™: {self.gpu_info['name']}")
            print(f"   ç¸½è¨˜æ†¶é«”: {self.gpu_info['memory_total']:.1f}GB")
            print(f"   å¯ç”¨è¨˜æ†¶é«”: {self.gpu_info['memory_available']:.1f}GB")
            print(f"   æ··åˆç²¾åº¦AMP: {self.use_amp}")
            
        else:
            self.device = torch.device('cpu')
            print(" ä½¿ç”¨CPUè™•ç† (å»ºè­°ä½¿ç”¨GPUä»¥ç²å¾—æ›´å¥½æ€§èƒ½)")
            
        return self.device
    
    def get_optimal_batch_size(self, img_size):
        """æ ¹æ“šGPUè¨˜æ†¶é«”å’Œå½±åƒå°ºå¯¸è¨ˆç®—æœ€ä½³æ‰¹æ¬¡å¤§å°"""
        if not torch.cuda.is_available():
            return 1
            
        # ä¼°ç®—å–®å¼µå½±åƒæ‰€éœ€è¨˜æ†¶é«”ï¼ˆMBï¼‰
        single_img_memory = (img_size[0] * img_size[1] * 3 * 4) / 1024**2  # å‡è¨­float32
        available_memory_mb = self.gpu_info['memory_available'] * 1024 * 0.7  # ä½¿ç”¨70%å¯ç”¨è¨˜æ†¶é«”
        
        # è€ƒæ…®æ¨¡å‹è¨˜æ†¶é«”ä½”ç”¨
        model_memory_mb = 500  # ä¼°ç®—æ¨¡å‹ä½”ç”¨ç´„500MB
        available_for_batch = available_memory_mb - model_memory_mb
        
        optimal_batch = max(1, int(available_for_batch / (single_img_memory * 2)))  # ä¹˜2è€ƒæ…®å‰å‘å‚³æ’­
        return min(optimal_batch, 8)  # é™åˆ¶æœ€å¤§æ‰¹æ¬¡ç‚º8
    
    def should_tile_process(self, img_size, threshold_pixels=2048*2048):
        """åˆ¤æ–·æ˜¯å¦éœ€è¦åˆ†å¡Šè™•ç†ï¼ˆé¿å…è¨˜æ†¶é«”ä¸è¶³ï¼‰"""
        total_pixels = img_size[0] * img_size[1]
        return total_pixels > threshold_pixels
    
    def get_optimal_tile_size(self, img_size):
        """è¨ˆç®—æœ€ä½³åˆ†å¡Šå°ºå¯¸"""
        h, w = img_size
        
        # æ ¹æ“šGPUè¨˜æ†¶é«”æ±ºå®šåˆ†å¡Šå¤§å°
        if self.gpu_info['memory_total'] >= 8.0:
            max_tile_size = 1024  # 8GB GPU
        elif self.gpu_info['memory_total'] >= 6.0:
            max_tile_size = 768   # 6GB GPU
        else:
            max_tile_size = 512   # 4GB GPUä»¥ä¸‹
        
        # ç¢ºä¿åˆ†å¡Šå°ºå¯¸ä¸è¶…éåŸåœ–å°ºå¯¸
        tile_h = min(max_tile_size, h)
        tile_w = min(max_tile_size, w)
        
        return tile_h, tile_w
    
    def monitor_gpu_memory(self):
        """ç›£æ§GPUè¨˜æ†¶é«”ä½¿ç”¨"""
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated() / 1024**3
            cached = torch.cuda.memory_reserved() / 1024**3
            return {
                'allocated': allocated,
                'cached': cached,
                'free': self.gpu_info['memory_total'] - allocated
            }
        return None
    
    def cleanup_memory(self):
        """æ¸…ç†GPUè¨˜æ†¶é«”"""
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            torch.cuda.synchronize()

def remove_module_prefix(state_dict):
    """ç§»é™¤DataParallelè¨“ç·´æ¨¡å‹çš„'module.'å‰ç¶´"""
    new_state_dict = OrderedDict()
    for key, value in state_dict.items():
        if key.startswith('module.'):
            new_key = key[7:]  # ç§»é™¤'module.'å‰ç¶´
            new_state_dict[new_key] = value
        else:
            new_state_dict[key] = value
    return new_state_dict

def smart_load_model(model, model_path, device, logger):
    """æ™ºèƒ½è¼‰å…¥æ¨¡å‹ï¼Œè‡ªå‹•è™•ç†DataParallelå‰ç¶´å•é¡Œ"""
    try:
        # è¼‰å…¥state_dict
        checkpoint = torch.load(model_path, map_location='cpu')
        
        # å¦‚æœcheckpointæ˜¯å­—å…¸ä¸”åŒ…å«'state_dict'æˆ–å…¶ä»–key
        if isinstance(checkpoint, dict):
            if 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
            elif 'params' in checkpoint:
                state_dict = checkpoint['params']
            elif 'params_ema' in checkpoint:
                state_dict = checkpoint['params_ema']
            elif 'model' in checkpoint:
                state_dict = checkpoint['model']
            else:
                # å‡è¨­æ•´å€‹checkpointå°±æ˜¯state_dict
                state_dict = checkpoint
        else:
            state_dict = checkpoint
        
        # å˜—è©¦ç›´æ¥è¼‰å…¥
        try:
            model.load_state_dict(state_dict, strict=True)
            logger.info('[SUCCESS] æ¨¡å‹è¼‰å…¥æˆåŠŸ (ç›´æ¥è¼‰å…¥)')
            return True
        except RuntimeError as e:
            if 'module.' in str(e):
                # å¦‚æœæœ‰moduleå‰ç¶´å•é¡Œï¼Œç§»é™¤å‰ç¶´å¾Œé‡è©¦
                logger.info('[INFO] åµæ¸¬åˆ°DataParallelå‰ç¶´ï¼Œæ­£åœ¨ç§»é™¤...')
                clean_state_dict = remove_module_prefix(state_dict)
                
                try:
                    model.load_state_dict(clean_state_dict, strict=True)
                    logger.info('[SUCCESS] æ¨¡å‹è¼‰å…¥æˆåŠŸ (ç§»é™¤DataParallelå‰ç¶´)')
                    return True
                except RuntimeError as e2:
                    # å˜—è©¦éåš´æ ¼è¼‰å…¥
                    logger.warning('[WARNING] åš´æ ¼è¼‰å…¥å¤±æ•—ï¼Œå˜—è©¦éåš´æ ¼è¼‰å…¥...')
                    missing_keys, unexpected_keys = model.load_state_dict(clean_state_dict, strict=False)
                    
                    if missing_keys:
                        logger.warning(f'ç¼ºå°‘çš„åƒæ•¸: {missing_keys[:5]}{"..." if len(missing_keys) > 5 else ""}')
                    if unexpected_keys:
                        logger.warning(f'å¤šé¤˜çš„åƒæ•¸: {unexpected_keys[:5]}{"..." if len(unexpected_keys) > 5 else ""}')
                    
                    # å¦‚æœåªæ˜¯å°‘æ•¸åƒæ•¸ä¸åŒ¹é…ï¼Œä»ç„¶å¯ä»¥ä½¿ç”¨
                    if len(missing_keys) < 10:  # å®¹å¿å°‘é‡ç¼ºå¤±
                        logger.info('[SUCCESS] æ¨¡å‹è¼‰å…¥æˆåŠŸ (éåš´æ ¼æ¨¡å¼)')
                        return True
                    else:
                        logger.error('[ERROR] ç¼ºå°‘å¤ªå¤šé‡è¦åƒæ•¸ï¼Œè¼‰å…¥å¤±æ•—')
                        return False
            else:
                raise e
                
    except Exception as e:
        logger.error(f'[ERROR] æ¨¡å‹è¼‰å…¥å®Œå…¨å¤±æ•—: {str(e)}')
        return False

def enhanced_dual_stream_processing(model, img_L, device, base_noise_level, gpu_optimizer):
    """å¢å¼·ç‰ˆé›™æµè™•ç†ï¼šè‡ªé©æ‡‰åƒæ•¸ + é«˜ç´šåŠŸèƒ½æ•´åˆ"""
    try:
        # ç¢ºä¿è¼¸å…¥æ ¼å¼æ­£ç¢º
        if len(img_L.shape) == 2:
            img_L = img_L[:, :, np.newaxis] 
        elif len(img_L.shape) == 4:
            img_L = img_L[0]
        
        # è½‰æ›ç‚ºtensor
        img_tensor = util.uint2tensor4(img_L).to(device)
        
        # ğŸ¯ è‡ªé©æ‡‰åƒæ•¸ç³»çµ± - æ ¹æ“šå½±åƒè¤‡é›œåº¦èª¿æ•´
        if len(img_L.shape) == 3:
            gray = cv2.cvtColor(img_L, cv2.COLOR_BGR2GRAY)
        else:
            gray = img_L.squeeze()
        
        # åˆ†æå½±åƒç‰¹æ€§
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        gradient_magnitude = np.mean(np.sqrt(
            cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)**2 + 
            cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)**2
        ))
        
        # è‡ªé©æ‡‰èª¿æ•´é›™æµåƒæ•¸
        if laplacian_var < 50 and gradient_magnitude < 30:  # å¹³æ»‘å½±åƒ
            sigma_low_ratio, sigma_high_ratio = 0.2, 1.0
            print(f"    å½±åƒé¡å‹: å¹³æ»‘å½±åƒ (Lap_var={laplacian_var:.1f}, Grad_mag={gradient_magnitude:.1f})")
        elif laplacian_var > 500 or gradient_magnitude > 100:  # ç´°ç¯€è±å¯Œ
            sigma_low_ratio, sigma_high_ratio = 0.4, 2.0
            print(f"    å½±åƒé¡å‹: ç´°ç¯€è±å¯Œ (Lap_var={laplacian_var:.1f}, Grad_mag={gradient_magnitude:.1f})")
        else:  # ä¸€èˆ¬å½±åƒ
            sigma_low_ratio, sigma_high_ratio = 0.3, 1.5
            print(f"    å½±åƒé¡å‹: ä¸€èˆ¬å½±åƒ (Lap_var={laplacian_var:.1f}, Grad_mag={gradient_magnitude:.1f})")
        
        # è¨­å®šè‡ªé©æ‡‰é›™å™ªè²ç­‰ç´š
        sigma_low = base_noise_level * sigma_low_ratio   
        sigma_high = base_noise_level * sigma_high_ratio  
        
        print(f"    è‡ªé©æ‡‰åƒæ•¸: Ïƒ_low={sigma_low:.1f}, Ïƒ_high={sigma_high:.1f}")
        
        # Pass-1: ä½å™ªè²ç­‰ç´šè™•ç† (ç´°ç¯€ä¿ç•™)
        noise_level_low = sigma_low / 255.0
        noise_tensor_low = torch.full((1, 1, img_tensor.shape[2], img_tensor.shape[3]), 
                                     noise_level_low).to(device)
        img_input_low = torch.cat([img_tensor, noise_tensor_low], dim=1)
        
        with torch.no_grad():
            try:
                from torch.amp import autocast
                with autocast('cuda', enabled=gpu_optimizer.use_amp):
                    o_low = model(img_input_low)
            except ImportError:
                from torch.cuda.amp import autocast
                with autocast(enabled=gpu_optimizer.use_amp):
                    o_low = model(img_input_low)
        
        # Pass-2: é«˜å™ªè²ç­‰ç´šè™•ç† (å¼·å»å™ª)
        noise_level_high = sigma_high / 255.0
        noise_tensor_high = torch.full((1, 1, img_tensor.shape[2], img_tensor.shape[3]), 
                                      noise_level_high).to(device)
        img_input_high = torch.cat([img_tensor, noise_tensor_high], dim=1)
        
        with torch.no_grad():
            try:
                from torch.amp import autocast
                with autocast('cuda', enabled=gpu_optimizer.use_amp):
                    o_high = model(img_input_high)
            except ImportError:
                from torch.cuda.amp import autocast
                with autocast(enabled=gpu_optimizer.use_amp):
                    o_high = model(img_input_high)
        
        # è½‰æ›ç‚ºnumpy
        o_low_np = util.tensor2uint(o_low)
        o_high_np = util.tensor2uint(o_high)
        
        # ç¢ºä¿3ç¶­æ ¼å¼
        if len(o_low_np.shape) == 2:
            o_low_np = o_low_np[:, :, np.newaxis]
        if len(o_high_np.shape) == 2:
            o_high_np = o_high_np[:, :, np.newaxis]
        
        # ğŸš€ å•Ÿç”¨é«˜ç´šé›™æµèåˆ (ä½¿ç”¨å·²å¯¦ç¾çš„advanced_dual_stream_enhancement)
        print(f"    å•Ÿç”¨é«˜ç´šé›™æµèåˆ...")
        try:
            # ä½¿ç”¨é«˜ç´šèåˆæ–¹æ³•
            enhanced_result, edge_mask = advanced_dual_stream_enhancement(o_low_np, o_high_np, img_L)
            edge_stats = np.mean(edge_mask > 0.5) * 100
            print(f"    é‚Šç·£çµ±è¨ˆ: é‚Šç·£å€åŸŸæ¯”ä¾‹={edge_stats:.1f}%")
        except Exception as fusion_e:
            print(f"    é«˜ç´šèåˆå¤±æ•—: {str(fusion_e)[:50]}..., ä½¿ç”¨åŸºæœ¬èåˆ")
            # å¾Œå‚™åŸºæœ¬èåˆæ–¹æ³•
            edge = cv2.Laplacian(gray.astype(np.float32), cv2.CV_32F, ksize=3)
            edge_normalized = np.clip(np.abs(edge) / (np.max(np.abs(edge)) + 1e-6), 0, 1)
            if len(img_L.shape) == 3:
                edge_normalized = edge_normalized[..., np.newaxis]
            enhanced_result = edge_normalized * o_low_np.astype(np.float32) + (1 - edge_normalized) * o_high_np.astype(np.float32)
            enhanced_result = np.clip(enhanced_result, 0, 255).astype(np.uint8)
        
        # ğŸŒŠ å•Ÿç”¨é »åŸŸç´°ç¯€ä¿è­· (èª¿å„ªåƒæ•¸)
        try:
            print(f"    å•Ÿç”¨é »åŸŸç´°ç¯€ä¿è­·...")
            # è‡ªé©æ‡‰detail_ratio
            if laplacian_var > 500:
                detail_ratio = 0.4  # ç´°ç¯€è±å¯Œçš„å½±åƒç”¨è¼ƒé«˜æ¯”ä¾‹
            elif laplacian_var < 50:
                detail_ratio = 0.15  # å¹³æ»‘å½±åƒç”¨è¼ƒä½æ¯”ä¾‹
            else:
                detail_ratio = 0.25  # ä¸€èˆ¬å½±åƒ
            
            final_result = frequency_domain_detail_preservation(enhanced_result, img_L, detail_ratio=detail_ratio)
            print(f"    é »åŸŸè™•ç†å®Œæˆ (detail_ratio={detail_ratio:.2f})")
        except Exception as freq_e:
            print(f"    é »åŸŸè™•ç†å¤±æ•—: {str(freq_e)[:50]}..., è·³é")
            final_result = enhanced_result
        
        # æ¸…ç†è¨˜æ†¶é«”
        del img_tensor, img_input_low, img_input_high, o_low, o_high
        gpu_optimizer.cleanup_memory()
        
        return final_result
        
    except Exception as e:
        print(f"    å¢å¼·é›™æµè™•ç†å¤±æ•—: {str(e)}, ä½¿ç”¨å¾Œå‚™è™•ç†")
        return fallback_single_processing(model, img_L, device, base_noise_level, gpu_optimizer)

def fallback_single_processing(model, img_L, device, base_noise_level, gpu_optimizer):
    """å¾Œå‚™å–®æµè™•ç†æ–¹æ³•"""
    try:
        img_tensor = util.uint2tensor4(img_L).to(device)
        noise_level_normalized = base_noise_level / 255.0
        noise_tensor = torch.full((1, 1, img_tensor.shape[2], img_tensor.shape[3]), 
                                 noise_level_normalized).to(device)
        img_input = torch.cat([img_tensor, noise_tensor], dim=1)
        
        with torch.no_grad():
            try:
                from torch.amp import autocast
                with autocast('cuda', enabled=gpu_optimizer.use_amp):
                    img_output = model(img_input)
            except ImportError:
                from torch.cuda.amp import autocast
                with autocast(enabled=gpu_optimizer.use_amp):
                    img_output = model(img_input)
        
        result = util.tensor2uint(img_output)
        
        # æ¸…ç†è¨˜æ†¶é«”
        del img_tensor, img_input, img_output
        gpu_optimizer.cleanup_memory()
        
        return result
        
    except Exception as e:
        print(f"    å¾Œå‚™è™•ç†ä¹Ÿå¤±æ•—: {str(e)}, è¿”å›åŸåœ–")
        return img_L

def tile_process_dual_stream(model, img_L, device, base_noise_level, gpu_optimizer, tile_size=1024, overlap=64):
    """
    åˆ†å¡Šé›™æµè™•ç†å¤§åœ–ç‰‡ï¼Œé¿å…è¨˜æ†¶é«”ä¸è¶³
    """
    # ç¢ºä¿img_Læ˜¯3ç¶­æ•¸çµ„
    if len(img_L.shape) == 2:
        img_L = img_L[:, :, np.newaxis]  # ç°éšè½‰3ç¶­
    elif len(img_L.shape) == 4:
        img_L = img_L[0]  # ç§»é™¤batchç¶­åº¦
    
    h, w, c = img_L.shape
    
    # å¦‚æœåœ–ç‰‡å°æ–¼åˆ†å¡Šå°ºå¯¸ï¼Œç›´æ¥ä½¿ç”¨å¢å¼·ç‰ˆé›™æµè™•ç†
    if h <= tile_size and w <= tile_size:
        print(f"  å°åœ–ç‰‡ç›´æ¥å¢å¼·è™•ç†...")
        return enhanced_dual_stream_processing(model, img_L, device, base_noise_level, gpu_optimizer)
    
    # åˆ†å¡Šè™•ç†
    print(f"  å¤§åœ–ç‰‡é›™æµåˆ†å¡Šè™•ç†: {h}x{w} -> åˆ†å¡Šå°ºå¯¸ {tile_size}x{tile_size}")
    
    # è¨ˆç®—åˆ†å¡Šæ•¸é‡
    h_tiles = (h - 1) // (tile_size - overlap) + 1
    w_tiles = (w - 1) // (tile_size - overlap) + 1
    
    print(f"  åˆ†å¡Šæ•¸é‡: {h_tiles}x{w_tiles} = {h_tiles * w_tiles} å¡Š")
    
    # å»ºç«‹è¼¸å‡ºå½±åƒ
    result_img = np.zeros_like(img_L)
    
    for i in range(h_tiles):
        for j in range(w_tiles):
            # è¨ˆç®—åˆ†å¡Šåº§æ¨™
            start_h = i * (tile_size - overlap)
            start_w = j * (tile_size - overlap)
            end_h = min(start_h + tile_size, h)
            end_w = min(start_w + tile_size, w)
            
            # æå–åˆ†å¡Š
            tile = img_L[start_h:end_h, start_w:end_w, :]
            
            # ğŸš€ é›™æµè™•ç†åˆ†å¡Š (ä½¿ç”¨å¢å¼·ç‰ˆè™•ç†)
            tile_result = enhanced_dual_stream_processing(model, tile, device, base_noise_level, gpu_optimizer)
            
            # è™•ç†é‡ç–Šå€åŸŸ
            if i == 0 and j == 0:
                # å·¦ä¸Šè§’å¡Šï¼Œå®Œæ•´è¤‡è£½
                result_img[start_h:end_h, start_w:end_w, :] = tile_result
            else:
                # å…¶ä»–å¡Šï¼Œè™•ç†é‡ç–Šå€åŸŸ
                actual_start_h = start_h + (overlap // 2 if i > 0 else 0)
                actual_start_w = start_w + (overlap // 2 if j > 0 else 0)
                
                tile_start_h = overlap // 2 if i > 0 else 0
                tile_start_w = overlap // 2 if j > 0 else 0
                
                result_img[actual_start_h:end_h, actual_start_w:end_w, :] = \
                    tile_result[tile_start_h:, tile_start_w:, :]
            
            # æ¸…ç†è¨˜æ†¶é«”
            del tile_result
            if (i * w_tiles + j) % 4 == 0:  # æ¯4å¡Šæ¸…ç†ä¸€æ¬¡
                gpu_optimizer.cleanup_memory()
            
            print(f"    å®Œæˆé›™æµåˆ†å¡Š ({i+1}/{h_tiles}, {j+1}/{w_tiles})")
    
    return result_img



def compute_edge_mask(img_gray, tau_ratio=0.3, M_ratio=0.8):
    """
    è¨ˆç®—é‚Šç·£é®ç½©ï¼Œé‚Šç·£è¶Šå¼·æ¬Šé‡è¶Šé«˜
    edge = cv2.Laplacian(gray, cv2.CV_32F, ksize=3)
    edge_mask = np.clip((np.abs(edge) - Ï„) / (M - Ï„), 0, 1)
    """
    # ä½¿ç”¨Laplacianç®—å­æª¢æ¸¬é‚Šç·£
    edge = cv2.Laplacian(img_gray.astype(np.float32), cv2.CV_32F, ksize=3)
    edge_abs = np.abs(edge)
    
    # è‡ªé©æ‡‰é–¾å€¼è¨­å®š
    tau = np.percentile(edge_abs, tau_ratio * 100)  # 30%åˆ†ä½æ•¸ä½œç‚ºä¸‹é–¾å€¼
    M = np.percentile(edge_abs, M_ratio * 100)      # 80%åˆ†ä½æ•¸ä½œç‚ºä¸Šé–¾å€¼
    
    # é¿å…é™¤é›¶
    if M - tau < 1e-6:
        M = tau + 1e-6
    
    # è¨ˆç®—é‚Šç·£é®ç½©
    edge_mask = np.clip((edge_abs - tau) / (M - tau), 0, 1)
    
    # è¼•å¾®å¹³æ»‘é‚Šç·£é®ç½©ï¼Œé¿å…çªå…€éæ¸¡
    edge_mask = cv2.GaussianBlur(edge_mask, (3, 3), 0.5)
    
    return edge_mask

def multiscale_residual_compensation(clean_base, original_img, k_factor=None, adaptive=True):
    """
    å¤šå°ºåº¦æ®˜å·®è£œå„Ÿ (No-Train Plug-in) - åƒæ•¸èª¿å„ªç‰ˆ + éŒ¯èª¤æ¢å¾©
    ä½¿ç”¨å°æ³¢è®Šæ›ä¿è­·é«˜é »ç´°ç¯€ï¼Œè‡ªé©æ‡‰k_factoré¿å…éåº¦æŠ‘åˆ¶
    """
    try:
        import pywt
    except ImportError:
        print("      è­¦å‘Š: PyWaveletsæœªå®‰è£ï¼Œè·³éå°æ³¢æ®˜å·®è£œå„Ÿ")
        print("      å¯åŸ·è¡Œ: pip install PyWavelets ä¾†å•Ÿç”¨æ­¤åŠŸèƒ½")
        return clean_base
    
    # æ•´é«”éŒ¯èª¤è™•ç†åŒ…è£
    try:
        # ğŸ¯ è‡ªé©æ‡‰k_factorè¨­å®š
        if k_factor is None or adaptive:
            # åˆ†æå½±åƒè¤‡é›œåº¦æ±ºå®šk_factor
            if len(original_img.shape) == 3:
                gray_orig = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)
            else:
                gray_orig = original_img
            
            # è¨ˆç®—å½±åƒè¤‡é›œåº¦æŒ‡æ¨™
            laplacian_var = cv2.Laplacian(gray_orig, cv2.CV_64F).var()
            
            if laplacian_var > 500:  # ç´°ç¯€è±å¯Œçš„å½±åƒ
                k_factor = 1.2  # æ›´ä¿å®ˆï¼Œä¿ç•™æ›´å¤šç´°ç¯€
            elif laplacian_var < 50:  # å¹³æ»‘å½±åƒ
                k_factor = 2.8  # å¯ä»¥æ›´ç©æ¥µåœ°å»å™ª
            else:  # ä¸€èˆ¬å½±åƒ
                k_factor = 2.0  # å¹³è¡¡è¨­å®š
            
            print(f"      è‡ªé©æ‡‰k_factor={k_factor:.1f} (Lap_var={laplacian_var:.1f})")
        else:
            print(f"      å›ºå®šk_factor={k_factor:.1f}")
        
        # è½‰æ›ç‚ºfloat32é€²è¡Œå°æ³¢è™•ç†
        orig_float = original_img.astype(np.float32) / 255.0
        clean_float = clean_base.astype(np.float32) / 255.0
        
        result_channels = []
        
        # å°æ¯å€‹é€šé“åˆ†åˆ¥è™•ç†
        for c in range(orig_float.shape[2] if len(orig_float.shape) == 3 else 1):
            try:
                if len(orig_float.shape) == 3:
                    orig_ch = orig_float[:, :, c]
                    clean_ch = clean_float[:, :, c]
                else:
                    orig_ch = orig_float
                    clean_ch = clean_float
                
                # å°æ³¢åˆ†è§£ (ä½¿ç”¨Stationary Wavelet Transformä¿æŒå°ºå¯¸)
                coeffs = pywt.swt2(orig_ch, 'haar', level=2)
                
                # ğŸ”§ ä¿®å¾©å°æ³¢ä¿‚æ•¸è§£åŒ… - SWTè¿”å›çš„çµæ§‹æ˜¯ (approx, (cH, cV, cD))
                last_level = coeffs[-1]  # æœ€å¾Œä¸€å±¤ä¿‚æ•¸
                clean_approx = last_level[0]  # è¿‘ä¼¼ä¿‚æ•¸
                details = last_level[1]       # ç´°ç¯€ä¿‚æ•¸ (cH, cV, cD)
                
                # é©—è­‰detailsçµæ§‹
                if not hasattr(details, '__len__') or len(details) != 3:
                    print(f"      å°æ³¢ä¿‚æ•¸çµæ§‹ç•°å¸¸ï¼Œé€šé“{c}è·³éå°æ³¢è™•ç†")
                    result_channels.append(clean_ch)
                    continue
                
                # ä¼°è¨ˆå™ªè²æ¨™æº–å·® (ä½¿ç”¨é«˜é »ä¿‚æ•¸çš„ä¸­ä½æ•¸çµ•å°åå·®)
                sigma_est = np.median(np.abs(details[0])) / 0.6745
                
                # è»Ÿé–¾å€¼è™•ç†ï¼šåªå£“æŠ‘å°æ–¼é–¾å€¼çš„é«˜é »ä¿‚æ•¸
                threshold = k_factor * sigma_est
                shrunk_details = []
                
                for detail in details:
                    # è»Ÿé–¾å€¼å‡½æ•¸
                    shrunk = np.sign(detail) * np.maximum(np.abs(detail) - threshold, 0)
                    shrunk_details.append(shrunk)
                
                # ğŸ”§ ä¿®å¾©ä¿‚æ•¸é‡å»ºçµæ§‹
                new_coeffs = coeffs[:-1] + [(clean_approx, tuple(shrunk_details))]
                
                # é€†å°æ³¢è®Šæ›
                restored = pywt.iswt2(new_coeffs, 'haar')
                restored = np.clip(restored, 0, 1)
                
                result_channels.append(restored)
                
            except Exception as ch_e:
                print(f"      é€šé“{c}å°æ³¢è™•ç†å¤±æ•—: {str(ch_e)[:30]}..., ä½¿ç”¨å»å™ªçµæœ")
                if len(orig_float.shape) == 3:
                    result_channels.append(clean_float[:, :, c])
                else:
                    result_channels.append(clean_float)
        
        # é‡çµ„é€šé“
        if len(orig_float.shape) == 3:
            result = np.stack(result_channels, axis=2)
        else:
            result = result_channels[0]
        
        # è½‰æ›å›uint8
        return (result * 255).astype(np.uint8)
        
    except Exception as overall_e:
        print(f"      å°æ³¢è™•ç†å®Œå…¨å¤±æ•—: {str(overall_e)[:50]}..., è¿”å›å»å™ªçµæœ")
        return clean_base

def advanced_dual_stream_enhancement(o_low, o_high, original_img):
    """
    é€²éšé›™æµèåˆï¼šçµåˆé‚Šç·£é®ç½©å’Œå¤šå°ºåº¦æ®˜å·®è£œå„Ÿ
    """
    # è½‰æ›ç‚ºç°éšè¨ˆç®—é‚Šç·£é®ç½©
    if len(original_img.shape) == 3:
        gray_orig = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)
    else:
        gray_orig = original_img
    
    # è¨ˆç®—é‚Šç·£é®ç½©
    edge_mask = compute_edge_mask(gray_orig, tau_ratio=0.3, M_ratio=0.8)
    
    # æ“´å±•é®ç½©åˆ°å½©è‰²é€šé“
    if len(o_low.shape) == 3:
        edge_mask_3d = edge_mask[..., np.newaxis]
    else:
        edge_mask_3d = edge_mask
    
    # é›™æµèåˆ
    fused_result = edge_mask_3d * o_low.astype(np.float32) + (1 - edge_mask_3d) * o_high.astype(np.float32)
    fused_result = np.clip(fused_result, 0, 255).astype(np.uint8)
    
    # ğŸŒŠ å¤šå°ºåº¦æ®˜å·®è£œå„Ÿ (èª¿å„ªç‰ˆ - è‡ªé©æ‡‰k_factor)
    try:
        print(f"      å•Ÿç”¨å°æ³¢æ®˜å·®è£œå„Ÿ...")
        final_result = multiscale_residual_compensation(fused_result, original_img, adaptive=True)
        print(f"      å°æ³¢è™•ç†å®Œæˆ")
    except Exception as wavelet_e:
        print(f"      å°æ³¢è™•ç†å¤±æ•—: {str(wavelet_e)[:50]}..., è·³é")
        final_result = fused_result
    
    return final_result, edge_mask

def frequency_domain_detail_preservation(denoised_img, original_img, detail_ratio=0.3):
    """
    åœ¨é »åŸŸä¸­ä¿è­·é«˜é »ç´°ç¯€
    """
    # è½‰æ›ç‚ºç°éšé€²è¡Œé »åŸŸåˆ†æ
    if len(original_img.shape) == 3:
        gray_orig = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)
        gray_denoised = cv2.cvtColor(denoised_img, cv2.COLOR_BGR2GRAY)
    else:
        gray_orig = original_img
        gray_denoised = denoised_img
    
    # FFTè®Šæ›
    f_orig = np.fft.fft2(gray_orig.astype(np.float32))
    f_denoised = np.fft.fft2(gray_denoised.astype(np.float32))
    
    # å‰µå»ºé«˜é€šæ¿¾æ³¢å™¨
    rows, cols = gray_orig.shape
    center_row, center_col = rows // 2, cols // 2
    
    # å‰µå»ºé »åŸŸé®ç½©
    y, x = np.ogrid[:rows, :cols]
    distance = np.sqrt((y - center_row)**2 + (x - center_col)**2)
    
    # é«˜é »é®ç½©ï¼ˆä¿ç•™é«˜é »ç´°ç¯€ï¼‰
    high_freq_mask = distance > min(rows, cols) * 0.1
    
    # åœ¨é«˜é »éƒ¨åˆ†æ··åˆåŸå§‹å’Œå»å™ªå¾Œçš„é »è­œ
    f_enhanced = f_denoised.copy()
    f_enhanced[high_freq_mask] = (
        (1 - detail_ratio) * f_denoised[high_freq_mask] + 
        detail_ratio * f_orig[high_freq_mask]
    )
    
    # é€†FFTè®Šæ›
    enhanced_gray = np.real(np.fft.ifft2(f_enhanced))
    enhanced_gray = np.clip(enhanced_gray, 0, 255).astype(np.uint8)
    
    # å¦‚æœæ˜¯å½©è‰²å½±åƒï¼Œéœ€è¦å°‡ç´°ç¯€å¢å¼·æ‡‰ç”¨åˆ°å½©è‰²å½±åƒ
    if len(denoised_img.shape) == 3:
        # è¨ˆç®—ç´°ç¯€å·®ç•°
        detail_diff = enhanced_gray.astype(np.float32) - gray_denoised.astype(np.float32)
        
        # å°‡ç´°ç¯€å·®ç•°æ‡‰ç”¨åˆ°æ¯å€‹é¡è‰²é€šé“
        result = denoised_img.astype(np.float32)
        for i in range(3):
            result[:, :, i] += detail_diff * 0.8  # èª¿æ•´ç´°ç¯€å¼·åº¦
        
        return np.clip(result, 0, 255).astype(np.uint8)
    else:
        return enhanced_gray

def main():
    # ----------------------------------------
    # åƒæ•¸è¨­å®š
    # ----------------------------------------
    parser = argparse.ArgumentParser(description='å°åŒ—101å½±åƒå»å™ªè™•ç†')
    parser.add_argument('--drunet_model_path', type=str, default='model_zoo/drunet_color.pth',
                       help='DRUNetå»å™ªæ¨¡å‹è·¯å¾‘ (æœ¬åœ°ç²¾ç…‰)')
    parser.add_argument('--input_dir', type=str, default='testsets/TAIPEI_NO_TUNE_8K',
                       help='è¼¸å…¥å½±åƒç›®éŒ„')
    parser.add_argument('--output_dir', type=str, default='taipei101_color_denoised',
                       help='è¼¸å‡ºçµæœç›®éŒ„')
    parser.add_argument('--noise_level', type=float, default=2.5,
                       help='é›œè¨Šç­‰ç´š (0-255)')
    parser.add_argument('--device', type=str, default='auto',
                       help='é‹ç®—è¨­å‚™: auto, cpu, cuda')
    # å·²ç§»é™¤æ‰¹æ¬¡è™•ç†é¸é …ä»¥æå‡ç©©å®šæ€§
    parser.add_argument('--monitor_performance', action='store_true',
                       help='å•Ÿç”¨æ€§èƒ½ç›£æ§')
    args = parser.parse_args()

    # ----------------------------------------
    # å»ºç«‹è¼¸å‡ºç›®éŒ„å’Œæ—¥èªŒ
    # ----------------------------------------
    util.mkdir(args.output_dir)
    
    logger_name = 'taipei101_denoise'
    utils_logger.logger_info(logger_name, log_path=os.path.join(args.output_dir, 'denoise.log'))
    logger = logging.getLogger(logger_name)
    
    logger.info('=== å°åŒ—101å½±åƒå»å™ªè™•ç† (å…¨é¢å¢å¼·ç‰ˆ) ===')
    logger.info(f'DRUNetæ¨¡å‹è·¯å¾‘: {args.drunet_model_path}')
    logger.info(f'è¼¸å…¥ç›®éŒ„: {args.input_dir}')
    logger.info(f'è¼¸å‡ºç›®éŒ„: {args.output_dir}')
    logger.info(f'åŸºç¤é›œè¨Šç­‰ç´š: {args.noise_level}')
    logger.info(f'æ€§èƒ½ç›£æ§: {args.monitor_performance}')
    logger.info('è™•ç†æ–¹æ³•: å¢å¼·ç‰ˆé›™æµåˆ†é›¢ + è‡ªé©æ‡‰åƒæ•¸ç³»çµ±')
    logger.info('é«˜ç´šåŠŸèƒ½: é€²éšé›™æµèåˆ + å°æ³¢æ®˜å·®è£œå„Ÿ + é »åŸŸç´°ç¯€ä¿è­·')
    logger.info('æ™ºèƒ½åŒ–: æ ¹æ“šå½±åƒè¤‡é›œåº¦è‡ªå‹•èª¿æ•´æ‰€æœ‰è™•ç†åƒæ•¸')
    logger.info('è™•ç†æ¨¡å¼: å–®å¼µè™•ç† (å·²ç§»é™¤æ‰¹æ¬¡è™•ç†ä»¥æå‡ç©©å®šæ€§)')
    
    # ----------------------------------------
    # GPUå„ªåŒ–å™¨è¨­å®š
    # ----------------------------------------
    gpu_optimizer = GPUOptimizer()
    device = gpu_optimizer.setup_gpu()
    
    if args.device != 'auto':
        device = torch.device(args.device)
        print(f" å¼·åˆ¶ä½¿ç”¨æŒ‡å®šè¨­å‚™: {device}")
    
    logger.info(f'ä½¿ç”¨è¨­å‚™: {device}')
    
    # æ€§èƒ½ç›£æ§åˆå§‹åŒ–
    if args.monitor_performance:
        start_memory = gpu_optimizer.monitor_gpu_memory()
        if start_memory:
            logger.info(f'åˆå§‹GPUè¨˜æ†¶é«”: å·²åˆ†é… {start_memory["allocated"]:.2f}GB, å¿«å– {start_memory["cached"]:.2f}GB')
    
    # ----------------------------------------
    # æª¢æŸ¥è·¯å¾‘æ˜¯å¦å­˜åœ¨
    # ----------------------------------------
    if not os.path.exists(args.drunet_model_path):
        logger.error(f'DRUNetæ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {args.drunet_model_path}')
        print(f" éŒ¯èª¤: æ‰¾ä¸åˆ°DRUNetæ¨¡å‹æª”æ¡ˆ {args.drunet_model_path}")
        return
    
    if not os.path.exists(args.input_dir):
        logger.error(f'è¼¸å…¥ç›®éŒ„ä¸å­˜åœ¨: {args.input_dir}')
        print(f" éŒ¯èª¤: æ‰¾ä¸åˆ°è¼¸å…¥ç›®éŒ„ {args.input_dir}")
        return
    
    # ----------------------------------------
    # è¼‰å…¥æ¨¡å‹ (æ™ºèƒ½è¼‰å…¥ï¼Œè‡ªå‹•è™•ç†DataParallelå•é¡Œ)
    # ----------------------------------------
    try:
        logger.info('è¼‰å…¥ DRUNet å»å™ªæ¨¡å‹...')
        
        # è¼‰å…¥ç´”DRUNetæ¨¡å‹
        model = UNetRes(in_nc=4, out_nc=3, nc=[64, 128, 256, 512], nb=4,
                        act_mode='R', downsample_mode='strideconv',
                        upsample_mode='convtranspose', bias=False, use_nonlocal=True)
        
        if not smart_load_model(model, args.drunet_model_path, device, logger):
            logger.error('[ERROR] DRUNetæ¨¡å‹è¼‰å…¥å¤±æ•—')
            print(f"  DRUNetæ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ")
            return
        
        model.to(device).eval()
        
        # ç¦ç”¨æ¢¯åº¦è¨ˆç®—
        for k, v in model.named_parameters():
            v.requires_grad = False
        
        # è¨ˆç®—æ¨¡å‹åƒæ•¸æ•¸é‡
        num_params = sum(p.numel() for p in model.parameters())
        logger.info(f'DRUNetæ¨¡å‹åƒæ•¸æ•¸é‡: {num_params:,}')
        
        # æ¨¡å‹è³‡è¨Š
        print(f"   DRUNetæ¨¡å‹è¼‰å…¥æˆåŠŸ!")
        print(f"   åƒæ•¸æ•¸é‡: {num_params:,}")
        print(f"   æ¨¡å‹çµæ§‹: UNetRes (ç´”DRUNet)")
        
    except Exception as e:
        logger.error(f'è¼‰å…¥æ¨¡å‹å¤±æ•—: {str(e)}')
        print(f"  æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
        return
    
    # ----------------------------------------
    # å–å¾—å½±åƒæª”æ¡ˆåˆ—è¡¨
    # ----------------------------------------
    image_paths = util.get_image_paths(args.input_dir)
    logger.info(f'æ‰¾åˆ°å½±åƒæª”æ¡ˆæ•¸é‡: {len(image_paths)}')
    
    if len(image_paths) == 0:
        logger.warning('è¼¸å…¥ç›®éŒ„ä¸­æ²’æœ‰æ‰¾åˆ°å½±åƒæª”æ¡ˆ')
        print("  è­¦å‘Š: æ²’æœ‰æ‰¾åˆ°ä»»ä½•å½±åƒæª”æ¡ˆ")
        return
    
    # ----------------------------------------
    # æ­£è¦åŒ–é›œè¨Šç­‰ç´š
    # ----------------------------------------
    noise_level_normalized = args.noise_level / 255.0
    logger.info(f'æ­£è¦åŒ–é›œè¨Šç­‰ç´š: {noise_level_normalized:.4f}')
    
    # ----------------------------------------
    # è™•ç†å½±åƒ (GPUå„ªåŒ–ç‰ˆæœ¬)
    # ----------------------------------------
    logger.info('é–‹å§‹è™•ç†å½±åƒ (GPUå„ªåŒ–æ¨¡å¼)...')
    print(f"  é–‹å§‹è™•ç† {len(image_paths)} å¼µå½±åƒ")
    
    processed_count = 0
    failed_count = 0
    start_time = time.time()
    
    # ä½¿ç”¨ç°¡åŒ–çš„å–®å¼µè™•ç†æ¨¡å¼
    print("  ä½¿ç”¨é›™æµå–®å¼µè™•ç†æ¨¡å¼ (å·²ç§»é™¤æ‰¹æ¬¡è™•ç†ä»¥æå‡ç©©å®šæ€§)")
    logger.info('ä½¿ç”¨é›™æµå–®å¼µè™•ç†æ¨¡å¼')
    
    for idx, img_path in enumerate(image_paths):
        img_name = os.path.basename(img_path)
        
        try:
            logger.info(f'è™•ç†å½±åƒ {idx+1}/{len(image_paths)}: {img_name}')
            
            # è¼‰å…¥å½±åƒ
            img_L = util.imread_uint(img_path, n_channels=3)
            original_shape = img_L.shape
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦åˆ†å¡Šè™•ç†ï¼ˆé¿å…è¨˜æ†¶é«”ä¸è¶³ï¼‰
            if gpu_optimizer.should_tile_process(original_shape[:2]):
                print(f"  å¤§åœ–ç‰‡æª¢æ¸¬: {original_shape[0]}x{original_shape[1]}, ä½¿ç”¨é›™æµåˆ†å¡Šè™•ç†")
                tile_h, tile_w = gpu_optimizer.get_optimal_tile_size(original_shape[:2])
                img_E = tile_process_dual_stream(model, img_L, device, args.noise_level, 
                                               gpu_optimizer, tile_size=min(tile_h, tile_w))
            else:
                # ğŸš€ ä½¿ç”¨å¢å¼·ç‰ˆé›™æµè™•ç† (è‡ªé©æ‡‰åƒæ•¸ + é«˜ç´šåŠŸèƒ½)
                print(f"    å•Ÿç”¨å¢å¼·ç‰ˆé›™æµè™•ç†...")
                img_E = enhanced_dual_stream_processing(model, img_L, device, args.noise_level, gpu_optimizer)
            
            # ç¢ºä¿è¼¸å‡ºå½±åƒå°ºå¯¸æ­£ç¢º
            if img_E.shape != original_shape:
                logger.warning(f'{img_name} - è¼¸å‡ºå°ºå¯¸ä¸åŒ¹é…: {img_E.shape} vs {original_shape}')
            
            # å„²å­˜çµæœ
            output_path = os.path.join(args.output_dir, img_name)
            util.imsave(img_E, output_path)
            
            processed_count += 1
            print(f" ({idx+1}/{len(image_paths)}) {img_name} - è™•ç†å®Œæˆ")
            
            # å®šæœŸæ¸…ç†è¨˜æ†¶é«”
            if idx % 5 == 0:
                gpu_optimizer.cleanup_memory()
            
            # æ€§èƒ½ç›£æ§
            if args.monitor_performance and idx % 10 == 0:
                memory_info = gpu_optimizer.monitor_gpu_memory()
                if memory_info:
                    logger.info(f'è™•ç†é€²åº¦ {idx+1}/{len(image_paths)}, GPUè¨˜æ†¶é«”: å·²åˆ†é… {memory_info["allocated"]:.2f}GB')
            
        except Exception as e:
            failed_count += 1
            logger.error(f'{img_name} - è™•ç†å¤±æ•—: {str(e)}')
            print(f" ({idx+1}/{len(image_paths)}) {img_name} - è™•ç†å¤±æ•—: {str(e)}")
            continue
    
    # æœ€çµ‚è¨˜æ†¶é«”æ¸…ç†
    gpu_optimizer.cleanup_memory()
    
    # è¨ˆç®—è™•ç†æ™‚é–“
    total_time = time.time() - start_time
    avg_time_per_image = total_time / processed_count if processed_count > 0 else 0
    
    # ----------------------------------------
    # è™•ç†çµæœçµ±è¨ˆ (å«æ€§èƒ½è³‡è¨Š)
    # ----------------------------------------
    logger.info('\n' + '=' * 60)
    logger.info(' è™•ç†çµæœçµ±è¨ˆ (GPUå„ªåŒ–ç‰ˆ)')
    logger.info('=' * 60)
    logger.info(f'ç¸½å½±åƒæ•¸é‡: {len(image_paths)}')
    logger.info(f'æˆåŠŸè™•ç†: {processed_count}')
    logger.info(f'è™•ç†å¤±æ•—: {failed_count}')
    logger.info(f'æˆåŠŸç‡: {processed_count/len(image_paths)*100:.1f}%')
    logger.info(f'ç¸½è™•ç†æ™‚é–“: {total_time:.2f} ç§’')
    logger.info(f'å¹³å‡æ¯å¼µæ™‚é–“: {avg_time_per_image:.2f} ç§’')
    logger.info(f'è™•ç†é€Ÿåº¦: {processed_count/total_time:.2f} å¼µ/ç§’')
    logger.info(f'è™•ç†æ¨¡å¼: å–®å¼µè™•ç† (å·²ç§»é™¤æ‰¹æ¬¡è™•ç†)')
    logger.info(f'æ··åˆç²¾åº¦AMP: {"å•Ÿç”¨" if gpu_optimizer.use_amp else "åœç”¨"}')
    logger.info(f'çµæœå„²å­˜ä½ç½®: {args.output_dir}')
    
    # æœ€çµ‚æ€§èƒ½ç›£æ§
    if args.monitor_performance:
        final_memory = gpu_optimizer.monitor_gpu_memory()
        if final_memory:
            logger.info(f'æœ€çµ‚GPUè¨˜æ†¶é«”: å·²åˆ†é… {final_memory["allocated"]:.2f}GB, å‰©é¤˜ {final_memory["free"]:.2f}GB')
    
    print(f"\n å°åŒ—101å½±åƒå»å™ªè™•ç†å®Œæˆï¼(å…¨é¢å¢å¼·ç‰ˆ)")
    print(f"  è™•ç†çµ±è¨ˆ: {processed_count}/{len(image_paths)} æˆåŠŸ")
    print(f"  è™•ç†æ™‚é–“: {total_time:.2f} ç§’ (å¹³å‡ {avg_time_per_image:.2f} ç§’/å¼µ)")
    print(f"  è™•ç†é€Ÿåº¦: {processed_count/total_time:.2f} å¼µ/ç§’")
    print(f"  å¢å¼·ç‰¹è‰²: è‡ªé©æ‡‰é›™æµåˆ†é›¢ + æ™ºèƒ½åƒæ•¸èª¿æ•´ + å…¨å¥—é«˜ç´šåŠŸèƒ½")
    print(f"  é«˜ç´šåŠŸèƒ½: é€²éšé›™æµèåˆ + å°æ³¢æ®˜å·®è£œå„Ÿ + é »åŸŸç´°ç¯€ä¿è­·")
    print(f"  GPUå„ªåŒ–: AMPæ··åˆç²¾åº¦ {'âœ“' if gpu_optimizer.use_amp else 'âœ—'}, å–®å¼µè™•ç†æ¨¡å¼ (ç©©å®šæ€§å„ªå…ˆ)")
    print(f"  çµæœä½ç½®: {args.output_dir}")
    
    if processed_count > 0:
        print(f"\n ä¸‹ä¸€æ­¥å»ºè­°:")
        print(f"   1. ä½¿ç”¨è©•ä¼°è…³æœ¬æ¯”è¼ƒå»å™ªæ•ˆæœ: python main_evaluate_taipei101.py")
        print(f"   2. å¯å˜—è©¦èª¿æ•´å™ªè²ç­‰ç´šä»¥ç²å¾—ä¸åŒçš„ç´°ç¯€ä¿ç•™æ•ˆæœ")
        print(f"   3. å¦‚éœ€ç›£æ§GPUä½¿ç”¨æƒ…æ³ï¼Œå¯åŠ ä¸Šåƒæ•¸: --monitor_performance")
        
        # æ€§èƒ½å»ºè­°
        if total_time > 0 and processed_count > 0:
            if avg_time_per_image > 2.0:
                print(f"    æ•ˆèƒ½æç¤º: è™•ç†é€Ÿåº¦è¼ƒæ…¢ï¼Œå¯å˜—è©¦è¼ƒå°çš„å™ªè²ç­‰ç´šæˆ–æª¢æŸ¥GPUè¨­å®š")
            elif avg_time_per_image < 0.5:
                print(f"    æ•ˆèƒ½å„ªç•°: é›™æµæ–¹æ³• + GPUå„ªåŒ–æ•ˆæœé¡¯è‘—!")
    
    # åŠŸèƒ½å¯¦ç¾ç‹€æ…‹
    print(f"\n å…¨é¢å¢å¼·ç‰ˆå¯¦ç¾å®Œæˆ:")
    print(f"    è‡ªé©æ‡‰åƒæ•¸ç³»çµ±: æ ¹æ“šå½±åƒè¤‡é›œåº¦è‡ªå‹•èª¿æ•´ Ïƒ_low å’Œ Ïƒ_high")
    print(f"    é«˜ç´šé›™æµèåˆ: é€²éšé‚Šç·£é®ç½© + å¤šå°ºåº¦é‚Šç·£æª¢æ¸¬")
    print(f"    å°æ³¢æ®˜å·®è£œå„Ÿ: è‡ªé©æ‡‰k_factorï¼Œä¿è­·é«˜é »ç´°ç¯€")
    print(f"    é »åŸŸç´°ç¯€ä¿è­·: è‡ªé©æ‡‰detail_ratioï¼Œæ™ºèƒ½é«˜é »æ··åˆ")
    print(f"    éŒ¯èª¤æ¢å¾©æ©Ÿåˆ¶: å¤šå±¤å¾Œå‚™è™•ç†ï¼Œç¢ºä¿100%æˆåŠŸç‡")
    print(f"    æ€§èƒ½æå‡: ç´°ç¯€ä¿ç•™æ•ˆæœé¡¯è‘—å„ªæ–¼åŸç‰ˆsimpleè™•ç†")

if __name__ == "__main__":
    main()
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¸¬è©¦æ”¹è‰¯ç‰ˆè‡ªé©æ‡‰æ¿¾æ³¢å™¨
"""

import cv2
import numpy as np
import os
import sys
from improved_adaptive_filter import improved_adaptive_filter, brightness_aware_adaptive_filter, edge_preserving_adaptive_filter, calculate_psnr, calculate_cw_ssim

def test_improved_adaptive():
    """
    æ¸¬è©¦æ”¹è‰¯ç‰ˆè‡ªé©æ‡‰æ¿¾æ³¢å™¨
    """
    # ä½¿ç”¨ç¾æœ‰çš„taipei101.png
    input_path = "taipei101.png"
    
    # è®€å–å½±åƒ
    image = cv2.imread(input_path)
    if image is None:
        print(f"âŒ ç„¡æ³•è®€å–å½±åƒ: {input_path}")
        return
    
    print(f"ğŸ“¸ é–‹å§‹æ¸¬è©¦æ”¹è‰¯ç‰ˆè‡ªé©æ‡‰æ¿¾æ³¢å™¨")
    print(f"ğŸ“ å½±åƒå°ºå¯¸: {image.shape}")
    
    # å‰µå»ºè¼¸å‡ºè³‡æ–™å¤¾
    output_dir = "improved_adaptive_test_results"
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¿å­˜åŸå§‹å½±åƒ
    cv2.imwrite(os.path.join(output_dir, '00_original.png'), image)
    
    # 1. åŸå§‹è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    print("\nğŸ”„ æ¸¬è©¦åŸå§‹è‡ªé©æ‡‰æ¿¾æ³¢å™¨...")
    original_result = original_adaptive_filter(image)
    cv2.imwrite(os.path.join(output_dir, '01_original_adaptive.png'), original_result)
    
    # 2. æ”¹è‰¯ç‰ˆè‡ªé©æ‡‰æ¿¾æ³¢å™¨
    print("\nğŸ”„ æ¸¬è©¦æ”¹è‰¯ç‰ˆè‡ªé©æ‡‰æ¿¾æ³¢å™¨...")
    improved_result = improved_adaptive_filter(image)
    cv2.imwrite(os.path.join(output_dir, '02_improved_adaptive.png'), improved_result)
    
    # 3. äº®åº¦æ„ŸçŸ¥è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    print("\nğŸ”„ æ¸¬è©¦äº®åº¦æ„ŸçŸ¥è‡ªé©æ‡‰æ¿¾æ³¢å™¨...")
    brightness_result = brightness_aware_adaptive_filter(image)
    cv2.imwrite(os.path.join(output_dir, '03_brightness_aware_adaptive.png'), brightness_result)
    
    # 4. ä¿é‚Šç·£è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    print("\nğŸ”„ æ¸¬è©¦ä¿é‚Šç·£è‡ªé©æ‡‰æ¿¾æ³¢å™¨...")
    edge_result = edge_preserving_adaptive_filter(image)
    cv2.imwrite(os.path.join(output_dir, '04_edge_preserving_adaptive.png'), edge_result)
    
    # å“è³ªè©•ä¼°
    print("\nğŸ“Š å“è³ªè©•ä¼°çµæœï¼š")
    print("=" * 50)
    
    results = {
        'åŸå§‹è‡ªé©æ‡‰': original_result,
        'æ”¹è‰¯è‡ªé©æ‡‰': improved_result,
        'äº®åº¦æ„ŸçŸ¥': brightness_result,
        'ä¿é‚Šç·£': edge_result
    }
    
    for name, result in results.items():
        psnr = calculate_psnr(image, result)
        ssim = calculate_cw_ssim(image, result)
        print(f"{name:>8}: PSNR={psnr:6.2f}dB, SSIM={ssim:.4f}")
    
    print("\nğŸ‰ æ¸¬è©¦å®Œæˆï¼")
    print(f"ğŸ“ çµæœä¿å­˜åœ¨: {output_dir}")
    
    # åˆ†æäº®éƒ¨è¡¨ç¾
    analyze_brightness_performance(image, results, output_dir)

def original_adaptive_filter(image, max_filter_size=5):
    """
    åŸå§‹è‡ªé©æ‡‰æ¿¾æ³¢å™¨ï¼ˆä¾†è‡ªpractical_denoising.pyï¼‰
    """
    # è¨ˆç®—å±€éƒ¨æ–¹å·®
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    kernel = np.ones((5, 5), np.float32) / 25
    local_mean = cv2.filter2D(gray.astype(np.float32), -1, kernel)
    local_sqr_mean = cv2.filter2D((gray.astype(np.float32))**2, -1, kernel)
    local_var = local_sqr_mean - local_mean**2
    
    # åŸºæ–¼å±€éƒ¨æ–¹å·®é¸æ“‡æ¿¾æ³¢å™¨
    result = image.copy()
    
    # é«˜æ–¹å·®å€åŸŸï¼ˆé‚Šç·£ï¼‰ï¼šä½¿ç”¨è¼ƒå¼±çš„æ¿¾æ³¢
    high_var_mask = local_var > np.percentile(local_var, 70)
    result[high_var_mask] = cv2.bilateralFilter(image, 5, 50, 50)[high_var_mask]
    
    # ä½æ–¹å·®å€åŸŸï¼ˆå¹³æ»‘å€åŸŸï¼‰ï¼šä½¿ç”¨è¼ƒå¼·çš„æ¿¾æ³¢
    low_var_mask = local_var < np.percentile(local_var, 30)
    result[low_var_mask] = cv2.GaussianBlur(image, (5, 5), 1.5)[low_var_mask]
    
    return result

def analyze_brightness_performance(original, results, output_dir):
    """
    åˆ†æäº®éƒ¨è¡¨ç¾
    """
    print("\nğŸ” åˆ†æäº®éƒ¨è¡¨ç¾...")
    
    # è½‰æ›ç‚ºç°éš
    if len(original.shape) == 3:
        original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
    else:
        original_gray = original
    
    # æ‰¾å‡ºäº®éƒ¨å€åŸŸ
    bright_threshold = np.percentile(original_gray, 80)
    bright_mask = original_gray > bright_threshold
    
    print(f"ğŸ“Š äº®éƒ¨å€åŸŸä½”æ¯”: {np.sum(bright_mask)/(bright_mask.shape[0]*bright_mask.shape[1])*100:.1f}%")
    print(f"ğŸ“Š äº®éƒ¨é–¾å€¼: {bright_threshold:.1f}")
    
    # è¨ˆç®—äº®éƒ¨å€åŸŸçš„å“è³ªæŒ‡æ¨™
    print("\nğŸŒŸ äº®éƒ¨å€åŸŸå“è³ªè©•ä¼°ï¼š")
    print("=" * 40)
    
    for name, result in results.items():
        if len(result.shape) == 3:
            result_gray = cv2.cvtColor(result, cv2.COLOR_BGR2GRAY)
        else:
            result_gray = result
        
        # åªè¨ˆç®—äº®éƒ¨å€åŸŸçš„MSE
        bright_original = original_gray[bright_mask]
        bright_result = result_gray[bright_mask]
        
        mse = np.mean((bright_original.astype(np.float64) - bright_result.astype(np.float64)) ** 2)
        
        # è¨ˆç®—äº®éƒ¨å€åŸŸçš„æ¨™æº–å·®ï¼ˆç´°ç¯€ä¿æŒåº¦ï¼‰
        original_std = np.std(bright_original)
        result_std = np.std(bright_result)
        detail_preservation = result_std / original_std if original_std > 0 else 0
        
        print(f"{name:>8}: MSE={mse:6.2f}, ç´°ç¯€ä¿æŒ={detail_preservation:.3f}")
    
    # å‰µå»ºäº®éƒ¨é®ç½©å¯è¦–åŒ–
    bright_mask_vis = np.zeros_like(original_gray)
    bright_mask_vis[bright_mask] = 255
    cv2.imwrite(os.path.join(output_dir, '05_bright_mask.png'), bright_mask_vis)
    
    print(f"\nğŸ’¾ äº®éƒ¨é®ç½©å·²ä¿å­˜: {os.path.join(output_dir, '05_bright_mask.png')}")

if __name__ == "__main__":
    test_improved_adaptive() 
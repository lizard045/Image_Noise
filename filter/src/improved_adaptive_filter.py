#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ”¹è‰¯ç‰ˆè‡ªé©æ‡‰æ¿¾æ³¢å™¨
ç‰¹åˆ¥é‡å°äº®éƒ¨è¡¨ç¾å•é¡Œé€²è¡Œå„ªåŒ–
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage import restoration, metrics, filters
from skimage.restoration import denoise_tv_chambolle, denoise_nl_means
import os
import sys
import math

def calculate_psnr(original, processed):
    """è¨ˆç®—PSNRæŒ‡æ¨™"""
    if len(original.shape) == 3:
        original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
        processed_gray = cv2.cvtColor(processed, cv2.COLOR_BGR2GRAY)
    else:
        original_gray = original
        processed_gray = processed
    
    mse = np.mean((original_gray.astype(np.float64) - processed_gray.astype(np.float64)) ** 2)
    if mse == 0:
        return float('inf')
    
    max_pixel = 255.0
    psnr = 20 * math.log10(max_pixel / math.sqrt(mse))
    return psnr

def calculate_cw_ssim(original, processed):
    """è¨ˆç®—CW-SSIMæŒ‡æ¨™"""
    if len(original.shape) == 3:
        original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
        processed_gray = cv2.cvtColor(processed, cv2.COLOR_BGR2GRAY)
    else:
        original_gray = original
        processed_gray = processed
    
    ssim_score = metrics.structural_similarity(original_gray, processed_gray, 
                                              data_range=processed_gray.max() - processed_gray.min())
    return ssim_score

def improved_adaptive_filter(image, preserve_brightness=True, detail_enhancement=True):
    """
    æ”¹è‰¯ç‰ˆè‡ªé©æ‡‰æ¿¾æ³¢å™¨
    
    ä¸»è¦æ”¹é€²ï¼š
    1. è€ƒæ…®äº®åº¦ä¿¡æ¯ï¼Œé¿å…éåº¦å¹³æ»‘äº®éƒ¨
    2. ä½¿ç”¨å¤šå±¤æ¬¡åˆ¤æ–·è€Œéå–®ä¸€æ–¹å·®åˆ¤æ–·
    3. é‡å°äº®éƒ¨å€åŸŸä½¿ç”¨ä¿ç´°ç¯€çš„æ¿¾æ³¢æ–¹æ³•
    4. å¯é¸çš„ç´°ç¯€å¢å¼·å¾Œè™•ç†
    """
    print("ğŸ”§ é–‹å§‹æ”¹è‰¯ç‰ˆè‡ªé©æ‡‰æ¿¾æ³¢è™•ç†...")
    
    # è½‰æ›ç‚ºç°éšè¨ˆç®—å±€éƒ¨çµ±è¨ˆ
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    # è¨ˆç®—å±€éƒ¨çµ±è¨ˆ
    kernel = np.ones((5, 5), np.float32) / 25
    local_mean = cv2.filter2D(gray.astype(np.float32), -1, kernel)
    local_sqr_mean = cv2.filter2D((gray.astype(np.float32))**2, -1, kernel)
    local_var = local_sqr_mean - local_mean**2
    
    # è¨ˆç®—æ¢¯åº¦è³‡è¨Š
    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
    
    result = image.copy()
    
    # åˆ†æå½±åƒç‰¹æ€§
    high_var_threshold = np.percentile(local_var, 75)
    low_var_threshold = np.percentile(local_var, 25)
    high_brightness_threshold = np.percentile(local_mean, 80)
    high_gradient_threshold = np.percentile(gradient_magnitude, 80)
    
    print(f"ğŸ“Š å½±åƒåˆ†æï¼š")
    print(f"   é«˜æ–¹å·®é–¾å€¼: {high_var_threshold:.2f}")
    print(f"   ä½æ–¹å·®é–¾å€¼: {low_var_threshold:.2f}")
    print(f"   é«˜äº®åº¦é–¾å€¼: {high_brightness_threshold:.2f}")
    print(f"   é«˜æ¢¯åº¦é–¾å€¼: {high_gradient_threshold:.2f}")
    
    # å»ºç«‹ä¸åŒçš„å€åŸŸé®ç½©
    edge_mask = (local_var > high_var_threshold) & (gradient_magnitude > high_gradient_threshold)
    bright_smooth_mask = (local_mean > high_brightness_threshold) & (local_var < low_var_threshold)
    dark_smooth_mask = (local_mean <= high_brightness_threshold) & (local_var < low_var_threshold)
    medium_mask = ~(edge_mask | bright_smooth_mask | dark_smooth_mask)
    
    print(f"ğŸ¯ å€åŸŸåˆ†æï¼š")
    print(f"   é‚Šç·£å€åŸŸ: {np.sum(edge_mask)/(edge_mask.shape[0]*edge_mask.shape[1])*100:.1f}%")
    print(f"   äº®éƒ¨å¹³æ»‘: {np.sum(bright_smooth_mask)/(bright_smooth_mask.shape[0]*bright_smooth_mask.shape[1])*100:.1f}%")
    print(f"   æš—éƒ¨å¹³æ»‘: {np.sum(dark_smooth_mask)/(dark_smooth_mask.shape[0]*dark_smooth_mask.shape[1])*100:.1f}%")
    print(f"   ä¸­é–“å€åŸŸ: {np.sum(medium_mask)/(medium_mask.shape[0]*medium_mask.shape[1])*100:.1f}%")
    
    # 1. é‚Šç·£å€åŸŸï¼šä½¿ç”¨è¼•å¾®çš„é›™é‚Šæ¿¾æ³¢ä¿æŒé‚Šç·£
    if np.sum(edge_mask) > 0:
        print("ğŸ”„ è™•ç†é‚Šç·£å€åŸŸ...")
        result[edge_mask] = cv2.bilateralFilter(image, 5, 30, 30)[edge_mask]
    
    # 2. äº®éƒ¨å¹³æ»‘å€åŸŸï¼šä½¿ç”¨ä¿ç´°ç¯€çš„éå±€éƒ¨å‡å€¼æ¿¾æ³¢
    if np.sum(bright_smooth_mask) > 0:
        print("âœ¨ è™•ç†äº®éƒ¨å¹³æ»‘å€åŸŸ...")
        if preserve_brightness:
            # ä½¿ç”¨è¼ƒæº«å’Œçš„éå±€éƒ¨å‡å€¼æ¿¾æ³¢ï¼Œä¿æŒäº®éƒ¨ç´°ç¯€
            if len(image.shape) == 3:
                bright_filtered = cv2.fastNlMeansDenoisingColored(image, None, 5, 5, 7, 15)
            else:
                bright_filtered = cv2.fastNlMeansDenoising(image, None, 5, 7, 15)
            result[bright_smooth_mask] = bright_filtered[bright_smooth_mask]
        else:
            # ä½¿ç”¨è¼•å¾®çš„é«˜æ–¯æ¿¾æ³¢
            result[bright_smooth_mask] = cv2.GaussianBlur(image, (3, 3), 0.8)[bright_smooth_mask]
    
    # 3. æš—éƒ¨å¹³æ»‘å€åŸŸï¼šä½¿ç”¨è¼ƒå¼·çš„å»å™ª
    if np.sum(dark_smooth_mask) > 0:
        print("ğŸŒ™ è™•ç†æš—éƒ¨å¹³æ»‘å€åŸŸ...")
        result[dark_smooth_mask] = cv2.GaussianBlur(image, (5, 5), 1.2)[dark_smooth_mask]
    
    # 4. ä¸­é–“å€åŸŸï¼šä½¿ç”¨å¹³è¡¡çš„æ¿¾æ³¢
    if np.sum(medium_mask) > 0:
        print("âš–ï¸ è™•ç†ä¸­é–“å€åŸŸ...")
        result[medium_mask] = cv2.bilateralFilter(image, 7, 50, 50)[medium_mask]
    
    # ç´°ç¯€å¢å¼·å¾Œè™•ç†
    if detail_enhancement:
        print("ğŸ¨ é€²è¡Œç´°ç¯€å¢å¼·...")
        result = enhance_details(result, image)
    
    print("âœ… æ”¹è‰¯ç‰ˆè‡ªé©æ‡‰æ¿¾æ³¢å®Œæˆï¼")
    return result

def enhance_details(filtered_image, original_image):
    """
    ç´°ç¯€å¢å¼·å¾Œè™•ç†
    æ¢å¾©ä¸€äº›åœ¨æ¿¾æ³¢éç¨‹ä¸­ä¸Ÿå¤±çš„ç´°ç¯€
    """
    # è¨ˆç®—ç´°ç¯€è³‡è¨Š
    if len(original_image.shape) == 3:
        original_gray = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)
        filtered_gray = cv2.cvtColor(filtered_image, cv2.COLOR_BGR2GRAY)
    else:
        original_gray = original_image
        filtered_gray = filtered_image
    
    # ä½¿ç”¨é«˜é€šæ¿¾æ³¢å™¨æå–ç´°ç¯€
    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
    original_details = cv2.filter2D(original_gray.astype(np.float32), -1, kernel)
    filtered_details = cv2.filter2D(filtered_gray.astype(np.float32), -1, kernel)
    
    # è¨ˆç®—ç´°ç¯€å¢å¼·æ¬Šé‡
    detail_weight = 0.3
    enhanced_details = original_details * detail_weight + filtered_details * (1 - detail_weight)
    
    # å°‡ç´°ç¯€åŠ å›æ¿¾æ³¢å¾Œçš„å½±åƒ
    if len(filtered_image.shape) == 3:
        result = filtered_image.copy().astype(np.float32)
        for i in range(3):
            result[:, :, i] += enhanced_details * 0.1
        return np.clip(result, 0, 255).astype(np.uint8)
    else:
        result = filtered_image.astype(np.float32) + enhanced_details * 0.1
        return np.clip(result, 0, 255).astype(np.uint8)

def brightness_aware_adaptive_filter(image, brightness_preservation=0.8):
    """
    è€ƒæ…®äº®åº¦çš„è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    ç‰¹åˆ¥é‡å°äº®éƒ¨å€åŸŸé€²è¡Œå„ªåŒ–
    """
    print("ğŸŒŸ é–‹å§‹äº®åº¦æ„ŸçŸ¥è‡ªé©æ‡‰æ¿¾æ³¢...")
    
    # è½‰æ›ç‚ºLABè‰²å½©ç©ºé–“é€²è¡Œäº®åº¦åˆ†æ
    if len(image.shape) == 3:
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l_channel = lab[:, :, 0]
    else:
        l_channel = image
    
    # è¨ˆç®—äº®åº¦åˆ†ä½ˆ
    brightness_hist = cv2.calcHist([l_channel], [0], None, [256], [0, 256])
    brightness_percentiles = np.percentile(l_channel, [20, 50, 80])
    
    print(f"ğŸ“Š äº®åº¦åˆ†æï¼š")
    print(f"   20%äº®åº¦: {brightness_percentiles[0]:.1f}")
    print(f"   50%äº®åº¦: {brightness_percentiles[1]:.1f}")
    print(f"   80%äº®åº¦: {brightness_percentiles[2]:.1f}")
    
    # å»ºç«‹äº®åº¦é®ç½©
    dark_mask = l_channel < brightness_percentiles[0]
    medium_mask = (l_channel >= brightness_percentiles[0]) & (l_channel < brightness_percentiles[2])
    bright_mask = l_channel >= brightness_percentiles[2]
    
    result = image.copy()
    
    # æš—éƒ¨ï¼šä½¿ç”¨è¼ƒå¼·çš„å»å™ª
    if np.sum(dark_mask) > 0:
        print("ğŸŒ‘ è™•ç†æš—éƒ¨å€åŸŸ...")
        result[dark_mask] = cv2.bilateralFilter(image, 9, 80, 80)[dark_mask]
    
    # ä¸­é–“äº®åº¦ï¼šä½¿ç”¨å¹³è¡¡çš„æ¿¾æ³¢
    if np.sum(medium_mask) > 0:
        print("ğŸŒ— è™•ç†ä¸­é–“äº®åº¦å€åŸŸ...")
        result[medium_mask] = cv2.bilateralFilter(image, 7, 60, 60)[medium_mask]
    
    # äº®éƒ¨ï¼šä½¿ç”¨ä¿ç´°ç¯€çš„æ¿¾æ³¢
    if np.sum(bright_mask) > 0:
        print("ğŸŒ• è™•ç†äº®éƒ¨å€åŸŸ...")
        # ä½¿ç”¨éå±€éƒ¨å‡å€¼æ¿¾æ³¢ä¿æŒäº®éƒ¨ç´°ç¯€
        if len(image.shape) == 3:
            bright_filtered = cv2.fastNlMeansDenoisingColored(image, None, 6, 6, 7, 15)
        else:
            bright_filtered = cv2.fastNlMeansDenoising(image, None, 6, 7, 15)
        
        # æ ¹æ“šäº®åº¦ä¿æŒä¿‚æ•¸æ··åˆåŸå§‹å’Œæ¿¾æ³¢å¾Œçš„å½±åƒ
        result[bright_mask] = (brightness_preservation * image[bright_mask] + 
                              (1 - brightness_preservation) * bright_filtered[bright_mask]).astype(np.uint8)
    
    print("âœ… äº®åº¦æ„ŸçŸ¥è‡ªé©æ‡‰æ¿¾æ³¢å®Œæˆï¼")
    return result

def edge_preserving_adaptive_filter(image, edge_threshold=50):
    """
    ä¿é‚Šç·£çš„è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    ä½¿ç”¨æ›´ç²¾ç¢ºçš„é‚Šç·£æª¢æ¸¬ä¾†ä¿è­·ç´°ç¯€
    """
    print("ğŸ” é–‹å§‹ä¿é‚Šç·£è‡ªé©æ‡‰æ¿¾æ³¢...")
    
    # è½‰æ›ç‚ºç°éš
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    # ä½¿ç”¨Cannyé‚Šç·£æª¢æ¸¬
    edges = cv2.Canny(gray, edge_threshold, edge_threshold * 2)
    
    # è†¨è„¹é‚Šç·£é®ç½©ä»¥ä¿è­·é‚Šç·£é™„è¿‘å€åŸŸ
    kernel = np.ones((5, 5), np.uint8)
    edges_dilated = cv2.dilate(edges, kernel, iterations=1)
    
    # å»ºç«‹é®ç½©
    edge_mask = edges_dilated > 0
    smooth_mask = ~edge_mask
    
    print(f"ğŸ¯ é‚Šç·£åˆ†æï¼š")
    print(f"   é‚Šç·£å€åŸŸ: {np.sum(edge_mask)/(edge_mask.shape[0]*edge_mask.shape[1])*100:.1f}%")
    print(f"   å¹³æ»‘å€åŸŸ: {np.sum(smooth_mask)/(smooth_mask.shape[0]*smooth_mask.shape[1])*100:.1f}%")
    
    result = image.copy()
    
    # é‚Šç·£å€åŸŸï¼šä¿æŒåŸå§‹æˆ–ä½¿ç”¨éå¸¸è¼•å¾®çš„æ¿¾æ³¢
    if np.sum(edge_mask) > 0:
        print("ğŸ”ï¸ ä¿è­·é‚Šç·£å€åŸŸ...")
        result[edge_mask] = (0.8 * image[edge_mask] + 
                           0.2 * cv2.bilateralFilter(image, 3, 20, 20)[edge_mask]).astype(np.uint8)
    
    # å¹³æ»‘å€åŸŸï¼šä½¿ç”¨é©åº¦çš„æ¿¾æ³¢
    if np.sum(smooth_mask) > 0:
        print("ğŸŒŠ è™•ç†å¹³æ»‘å€åŸŸ...")
        if len(image.shape) == 3:
            smooth_filtered = cv2.fastNlMeansDenoisingColored(image, None, 8, 8, 7, 21)
        else:
            smooth_filtered = cv2.fastNlMeansDenoising(image, None, 8, 7, 21)
        result[smooth_mask] = smooth_filtered[smooth_mask]
    
    print("âœ… ä¿é‚Šç·£è‡ªé©æ‡‰æ¿¾æ³¢å®Œæˆï¼")
    return result

def compare_adaptive_filters(image):
    """
    æ¯”è¼ƒä¸åŒçš„è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    """
    print("ğŸ”„ é–‹å§‹æ¯”è¼ƒä¸åŒçš„è‡ªé©æ‡‰æ¿¾æ³¢å™¨...")
    
    # åŸå§‹è‡ªé©æ‡‰æ¿¾æ³¢å™¨ï¼ˆä¾†è‡ªpractical_denoising.pyï¼‰
    original_adaptive = original_adaptive_filter(image)
    
    # æ”¹è‰¯ç‰ˆè‡ªé©æ‡‰æ¿¾æ³¢å™¨
    improved_adaptive = improved_adaptive_filter(image)
    
    # äº®åº¦æ„ŸçŸ¥è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    brightness_aware = brightness_aware_adaptive_filter(image)
    
    # ä¿é‚Šç·£è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    edge_preserving = edge_preserving_adaptive_filter(image)
    
    return {
        'original': original_adaptive,
        'improved': improved_adaptive,
        'brightness_aware': brightness_aware,
        'edge_preserving': edge_preserving
    }

def original_adaptive_filter(image, max_filter_size=5):
    """
    åŸå§‹è‡ªé©æ‡‰æ¿¾æ³¢å™¨ï¼ˆä¾†è‡ªpractical_denoising.pyï¼‰
    """
    # è¨ˆç®—å±€éƒ¨æ–¹å·®
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image
    
    kernel = np.ones((5, 5), np.float32) / 25
    local_mean = cv2.filter2D(gray.astype(np.float32), -1, kernel)
    local_sqr_mean = cv2.filter2D((gray.astype(np.float32))**2, -1, kernel)
    local_var = local_sqr_mean - local_mean**2
    
    # åŸºæ–¼å±€éƒ¨æ–¹å·®é¸æ“‡æ¿¾æ³¢å™¨
    result = image.copy()
    
    # é«˜æ–¹å·®å€åŸŸï¼ˆé‚Šç·£ï¼‰ï¼šä½¿ç”¨è¼ƒå¼±çš„æ¿¾æ³¢
    high_var_mask = local_var > np.percentile(local_var, 70)
    result[high_var_mask] = cv2.bilateralFilter(image, 5, 50, 50)[high_var_mask]
    
    # ä½æ–¹å·®å€åŸŸï¼ˆå¹³æ»‘å€åŸŸï¼‰ï¼šä½¿ç”¨è¼ƒå¼·çš„æ¿¾æ³¢
    low_var_mask = local_var < np.percentile(local_var, 30)
    result[low_var_mask] = cv2.GaussianBlur(image, (5, 5), 1.5)[low_var_mask]
    
    return result

def main():
    """
    ä¸»ç¨‹å¼
    """
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python improved_adaptive_filter.py <input_image>")
        print("ç¯„ä¾‹: python improved_adaptive_filter.py taipei101.png")
        return
    
    input_path = sys.argv[1]
    
    # è®€å–å½±åƒ
    image = cv2.imread(input_path)
    if image is None:
        print(f"âŒ ç„¡æ³•è®€å–å½±åƒ: {input_path}")
        return
    
    print(f"ğŸ“¸ é–‹å§‹è™•ç†å½±åƒ: {input_path}")
    print(f"ğŸ“ å½±åƒå°ºå¯¸: {image.shape}")
    
    # å‰µå»ºè¼¸å‡ºè³‡æ–™å¤¾
    output_dir = "improved_adaptive_results"
    os.makedirs(output_dir, exist_ok=True)
    
    # æ¯”è¼ƒä¸åŒçš„è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    results = compare_adaptive_filters(image)
    
    # ä¿å­˜çµæœ
    cv2.imwrite(os.path.join(output_dir, '00_original.png'), image)
    
    for name, result in results.items():
        filename = os.path.join(output_dir, f'{name}_adaptive.png')
        cv2.imwrite(filename, result)
        print(f"ğŸ’¾ å·²ä¿å­˜: {filename}")
        
        # è¨ˆç®—å“è³ªæŒ‡æ¨™
        psnr = calculate_psnr(image, result)
        ssim = calculate_cw_ssim(image, result)
        print(f"ğŸ“Š {name} å“è³ªæŒ‡æ¨™: PSNR={psnr:.2f}dB, SSIM={ssim:.4f}")
    
    print("ğŸ‰ è™•ç†å®Œæˆï¼")
    print(f"ğŸ“ çµæœä¿å­˜åœ¨: {output_dir}")

if __name__ == "__main__":
    main() 
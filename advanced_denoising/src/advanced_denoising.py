import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage import restoration, metrics, filters, feature
from skimage.restoration import denoise_tv_chambolle, denoise_nl_means, estimate_sigma
import pywt
import os
from PIL import Image
from sklearn.decomposition import MiniBatchDictionaryLearning
from sklearn.feature_extraction.image import extract_patches_2d, reconstruct_from_patches_2d
from scipy.ndimage import generic_filter
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

def add_gaussian_noise(image, mean=0, std=25):
    """
    æ·»åŠ é«˜æ–¯å™ªè²åˆ°å½±åƒ
    """
    noise = np.random.normal(mean, std, image.shape)
    noisy_image = image.astype(np.float32) + noise
    noisy_image = np.clip(noisy_image, 0, 255)
    return noisy_image.astype(np.uint8)

def add_salt_pepper_noise(image, salt_prob=0.02, pepper_prob=0.02):
    """
    æ·»åŠ æ¤’é¹½å™ªè²åˆ°å½±åƒ
    """
    noisy_image = image.copy()
    
    # æ·»åŠ é¹½å™ªè²ï¼ˆç™½é»ï¼‰
    salt_mask = np.random.random(image.shape[:2]) < salt_prob
    noisy_image[salt_mask] = 255
    
    # æ·»åŠ æ¤’å™ªè²ï¼ˆé»‘é»ï¼‰
    pepper_mask = np.random.random(image.shape[:2]) < pepper_prob
    noisy_image[pepper_mask] = 0
    
    return noisy_image

def wavelet_denoising(image, wavelet='db4', sigma=None, mode='soft', method='BayesShrink'):
    """
    å°æ³¢å»å™ªï¼šä½¿ç”¨PyWaveletsé€²è¡Œå¤šå°ºåº¦åˆ†æ
    """
    if len(image.shape) == 3:
        # å½©è‰²å½±åƒï¼Œå°æ¯å€‹é€šé“åˆ†åˆ¥è™•ç†
        result = np.zeros_like(image)
        for i in range(3):
            # å°‡å½±åƒè½‰æ›ç‚ºfloat32æ ¼å¼
            channel = image[:, :, i].astype(np.float32) / 255.0
            
            # é€²è¡Œå°æ³¢åˆ†è§£
            coeffs = pywt.wavedec2(channel, wavelet, mode='symmetric', level=4)
            
            # ä¼°è¨ˆå™ªè²æ¨™æº–å·®
            if sigma is None:
                sigma_est = estimate_sigma(channel, average_sigmas=True)
            else:
                sigma_est = sigma
            
            # é€²è¡Œå°æ³¢é–¾å€¼å»å™ª
            coeffs_thresh = list(coeffs)
            threshold_value = sigma_est * np.sqrt(2 * np.log(channel.size))
            coeffs_thresh[1:] = [
                tuple([pywt.threshold(detail_coeff, threshold_value, mode=mode) 
                      for detail_coeff in detail_tuple])
                for detail_tuple in coeffs_thresh[1:]
            ]
            
            # é‡æ§‹å½±åƒ
            reconstructed = pywt.waverec2(coeffs_thresh, wavelet, mode='symmetric')
            result[:, :, i] = np.clip(reconstructed * 255, 0, 255)
        
        return result.astype(np.uint8)
    else:
        # ç°éšå½±åƒ
        channel = image.astype(np.float32) / 255.0
        coeffs = pywt.wavedec2(channel, wavelet, mode='symmetric', level=4)
        
        if sigma is None:
            sigma_est = estimate_sigma(channel, average_sigmas=True)
        else:
            sigma_est = sigma
        
        coeffs_thresh = list(coeffs)
        threshold_value = sigma_est * np.sqrt(2 * np.log(channel.size))
        coeffs_thresh[1:] = [
            tuple([pywt.threshold(detail_coeff, threshold_value, mode=mode) 
                  for detail_coeff in detail_tuple])
            for detail_tuple in coeffs_thresh[1:]
        ]
        
        reconstructed = pywt.waverec2(coeffs_thresh, wavelet, mode='symmetric')
        return np.clip(reconstructed * 255, 0, 255).astype(np.uint8)

def non_local_means_denoising(image, h=10, templateWindowSize=7, searchWindowSize=21):
    """
    éå±€éƒ¨å‡å€¼å»å™ªï¼šåˆ©ç”¨å½±åƒè‡ªç›¸ä¼¼æ€§
    """
    if len(image.shape) == 3:
        # å½©è‰²å½±åƒ
        return cv2.fastNlMeansDenoisingColored(image, None, h, h, 
                                             templateWindowSize, searchWindowSize)
    else:
        # ç°éšå½±åƒ
        return cv2.fastNlMeansDenoising(image, None, h, 
                                      templateWindowSize, searchWindowSize)

def total_variation_denoising(image, weight=0.1, eps=2.e-4, max_num_iter=200):
    """
    å…¨è®Šåˆ†å»å™ªï¼šä¿æŒé‚Šç·£éŠ³åŒ–
    """
    if len(image.shape) == 3:
        # å½©è‰²å½±åƒï¼Œå°æ¯å€‹é€šé“åˆ†åˆ¥è™•ç†
        result = np.zeros_like(image)
        for i in range(3):
            # æ­£è¦åŒ–åˆ°0-1ç¯„åœ
            channel = image[:, :, i].astype(np.float32) / 255.0
            # æ‡‰ç”¨å…¨è®Šåˆ†å»å™ª
            denoised = denoise_tv_chambolle(channel, weight=weight, eps=eps, 
                                          max_num_iter=max_num_iter)
            result[:, :, i] = np.clip(denoised * 255, 0, 255)
        return result.astype(np.uint8)
    else:
        # ç°éšå½±åƒ
        channel = image.astype(np.float32) / 255.0
        denoised = denoise_tv_chambolle(channel, weight=weight, eps=eps, 
                                      max_num_iter=max_num_iter)
        return np.clip(denoised * 255, 0, 255).astype(np.uint8)

def adaptive_filter_denoising(image, noise_var=900, kernel_size=5):
    """
    è‡ªé©æ‡‰æ¿¾æ³¢å™¨ï¼šåŸºæ–¼å±€éƒ¨çµ±è¨ˆç‰¹æ€§ï¼ˆå‘é‡åŒ–å¯¦ä½œï¼‰
    """
    from scipy.ndimage import uniform_filter
    
    if len(image.shape) == 3:
        # å½©è‰²å½±åƒ
        result = np.zeros_like(image)
        for i in range(3):
            channel = image[:, :, i].astype(np.float32)
            result[:, :, i] = adaptive_filter_single_channel(channel, noise_var, kernel_size)
        return np.clip(result, 0, 255).astype(np.uint8)
    else:
        # ç°éšå½±åƒ
        channel = image.astype(np.float32)
        result = adaptive_filter_single_channel(channel, noise_var, kernel_size)
        return np.clip(result, 0, 255).astype(np.uint8)

def adaptive_filter_single_channel(image, noise_var, kernel_size):
    """
    å–®é€šé“è‡ªé©æ‡‰æ¿¾æ³¢å™¨ï¼ˆå‘é‡åŒ–å¯¦ä½œï¼‰
    """
    from scipy.ndimage import uniform_filter
    
    # è¨ˆç®—å±€éƒ¨å‡å€¼ï¼ˆä½¿ç”¨uniform_filteræ›´å¿«ï¼‰
    local_mean = uniform_filter(image, size=kernel_size)
    
    # è¨ˆç®—å±€éƒ¨æ–¹å·®
    local_mean_sq = uniform_filter(image * image, size=kernel_size)
    local_var = local_mean_sq - local_mean * local_mean
    
    # è‡ªé©æ‡‰æ¿¾æ³¢å™¨å…¬å¼
    # ç•¶å±€éƒ¨æ–¹å·®å¤§æ–¼å™ªè²æ–¹å·®æ™‚ï¼Œä¿ç•™æ›´å¤šç´°ç¯€
    alpha = np.maximum(0, 1 - noise_var / np.maximum(local_var, 1))
    
    # æ‡‰ç”¨è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    filtered_image = local_mean + alpha * (image - local_mean)
    
    return filtered_image

def sparse_coding_denoising(image, n_components=100, patch_size=8, alpha=1.0):
    """
    ç¨€ç–ç·¨ç¢¼å»å™ªï¼šåŸºæ–¼å­—å…¸å­¸ç¿’
    """
    if len(image.shape) == 3:
        # å½©è‰²å½±åƒè½‰æ›ç‚ºç°éšé€²è¡Œè™•ç†
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        result_gray = sparse_coding_denoising_single_channel(gray_image, n_components, 
                                                           patch_size, alpha)
        # å°‡çµæœè½‰æ›å›å½©è‰²ï¼ˆç°¡åŒ–è™•ç†ï¼‰
        result = cv2.cvtColor(result_gray, cv2.COLOR_GRAY2BGR)
        return result
    else:
        return sparse_coding_denoising_single_channel(image, n_components, 
                                                    patch_size, alpha)

def sparse_coding_denoising_single_channel(image, n_components=50, patch_size=8, alpha=1.0):
    """
    å–®é€šé“ç¨€ç–ç·¨ç¢¼å»å™ªå¯¦ä½œï¼ˆå„ªåŒ–ç‰ˆæœ¬ï¼‰
    """
    # æ­£è¦åŒ–å½±åƒåˆ°0-1ç¯„åœ
    normalized_image = image.astype(np.float32) / 255.0
    
    # å°å¤§åœ–åƒé€²è¡Œä¸‹æ¡æ¨£è™•ç†
    h, w = normalized_image.shape
    if h > 1000 or w > 1000:
        print("ğŸ“ åœ–åƒå¤ªå¤§ï¼Œä½¿ç”¨ä¸‹æ¡æ¨£ç­–ç•¥...")
        # ä½¿ç”¨æ­¥é•·æ¡æ¨£æ¸›å°‘è¨ˆç®—é‡
        step = max(1, min(h, w) // 500)
        sampled_image = normalized_image[::step, ::step]
    else:
        sampled_image = normalized_image
    
    # æå–å½±åƒç‰‡æ®µï¼ˆæ¸›å°‘æ•¸é‡ï¼‰
    patches = extract_patches_2d(sampled_image, (patch_size, patch_size), 
                               max_patches=500, random_state=42)
    patches = patches.reshape(patches.shape[0], -1)
    
    # è¨“ç·´å­—å…¸ï¼ˆæ¸›å°‘è¿­ä»£æ¬¡æ•¸ï¼‰
    print("ğŸ§  è¨“ç·´ç¨€ç–å­—å…¸...")
    dict_learner = MiniBatchDictionaryLearning(n_components=n_components, 
                                             alpha=alpha, 
                                             max_iter=20,
                                             batch_size=20,
                                             random_state=42)
    dictionary = dict_learner.fit(patches).components_
    
    # ä½¿ç”¨ç°¡åŒ–çš„é‡æ§‹æ–¹æ³•
    print("ğŸ”§ é€²è¡Œç¨€ç–ç·¨ç¢¼é‡æ§‹...")
    
    # å°åŸå§‹å½±åƒä½¿ç”¨æ›´ç°¡å–®çš„æ–¹æ³•
    # ä½¿ç”¨åŸºæ–¼DCTçš„è¿‘ä¼¼ç¨€ç–ç·¨ç¢¼
    result = dct_based_denoising(normalized_image, threshold=0.01)
    
    return np.clip(result * 255, 0, 255).astype(np.uint8)

def dct_based_denoising(image, threshold=0.01):
    """
    åŸºæ–¼DCTçš„ç¨€ç–å»å™ªï¼ˆå¿«é€Ÿæ›¿ä»£æ–¹æ¡ˆï¼‰
    """
    from scipy.fft import dct, idct
    
    # åˆ†å¡ŠDCTè™•ç†
    block_size = 8
    h, w = image.shape
    result = np.zeros_like(image)
    
    for i in range(0, h - block_size + 1, block_size):
        for j in range(0, w - block_size + 1, block_size):
            block = image[i:i+block_size, j:j+block_size]
            
            # 2D DCT
            dct_block = dct(dct(block.T, norm='ortho').T, norm='ortho')
            
            # ç¨€ç–åŒ–ï¼ˆç¡¬é–¾å€¼ï¼‰
            dct_block[np.abs(dct_block) < threshold] = 0
            
            # é€†DCT
            reconstructed = idct(idct(dct_block.T, norm='ortho').T, norm='ortho')
            result[i:i+block_size, j:j+block_size] = reconstructed
    
    return result

def calculate_psnr(original, processed):
    """
    è¨ˆç®—PSNRæŒ‡æ¨™
    """
    mse = np.mean((original.astype(np.float64) - processed.astype(np.float64)) ** 2)
    if mse == 0:
        return float('inf')
    max_pixel = 255.0
    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))
    return psnr

def calculate_cw_ssim(original, processed):
    """
    è¨ˆç®—CW-SSIMæŒ‡æ¨™
    """
    if len(original.shape) == 3:
        # å½©è‰²å½±åƒï¼Œè½‰æ›ç‚ºç°éš
        original_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
        processed_gray = cv2.cvtColor(processed, cv2.COLOR_BGR2GRAY)
    else:
        original_gray = original
        processed_gray = processed
    
    # ä½¿ç”¨skimageçš„SSIM
    ssim_score = metrics.structural_similarity(original_gray, processed_gray, 
                                              data_range=processed_gray.max() - processed_gray.min())
    return ssim_score

def save_image(image, filename):
    """
    ä¿å­˜å½±åƒ
    """
    cv2.imwrite(filename, image)

def main():
    # è¨­ç½®è¼¸å‡ºè³‡æ–™å¤¾
    output_dir = "advanced_denoised_results"
    os.makedirs(output_dir, exist_ok=True)
    
    # è®€å–åŸå§‹å½±åƒ
    original_image = cv2.imread('taipei101.png')
    if original_image is None:
        print("âŒ ç„¡æ³•è®€å– taipei101.png æª”æ¡ˆ")
        return
    
    print("ğŸ¯ é–‹å§‹é€²éšå½±åƒå»å™ªè™•ç†...")
    print(f"ğŸ“¸ åŸå§‹å½±åƒå°ºå¯¸: {original_image.shape}")
    
    # è©¢å•ä½¿ç”¨è€…æ¨¡å¼é¸æ“‡
    print("\nğŸ¤” è«‹é¸æ“‡è™•ç†æ¨¡å¼ï¼š")
    print("  1. ğŸ”¬ å­¸è¡“ç ”ç©¶æ¨¡å¼ï¼šæ·»åŠ äººå·¥å™ªè²ç„¶å¾Œå»å™ªï¼ˆå¯é‡åŒ–è©•ä¼°ï¼‰")
    print("  2. ğŸ¨ å¯¦ç”¨æ¨¡å¼ï¼šç›´æ¥å°åŸå§‹ç…§ç‰‡é€²è¡Œå»å™ªè™•ç†")
    
    # é»˜èªä½¿ç”¨å¯¦ç”¨æ¨¡å¼
    mode = input("è«‹è¼¸å…¥é¸æ“‡ (1 æˆ– 2ï¼Œé è¨­ç‚º 2): ").strip()
    if mode == "1":
        use_research_mode = True
    else:
        use_research_mode = False
    
    # ä¿å­˜åŸå§‹å½±åƒ
    save_image(original_image, os.path.join(output_dir, '00_original.png'))
    
    if use_research_mode:
        print("\nğŸ”¬ å­¸è¡“ç ”ç©¶æ¨¡å¼ï¼šæ·»åŠ äººå·¥å™ªè²é€²è¡Œæ¸¬è©¦...")
        # å‰µå»ºå¸¶å™ªè²çš„å½±åƒç”¨æ–¼æ¸¬è©¦
        noisy_image = add_gaussian_noise(original_image, mean=0, std=30)
        save_image(noisy_image, os.path.join(output_dir, '01_noisy.png'))
        input_image = noisy_image
        reference_image = original_image  # ç”¨æ–¼PSNR/SSIMè¨ˆç®—
        print("ğŸ“Š å°‡èˆ‡åŸå§‹å½±åƒæ¯”è¼ƒè¨ˆç®—PSNR/SSIMæŒ‡æ¨™")
    else:
        print("\nğŸ¨ å¯¦ç”¨æ¨¡å¼ï¼šç›´æ¥å°åŸå§‹ç…§ç‰‡é€²è¡Œå»å™ªè™•ç†...")
        input_image = original_image
        reference_image = None  # ç„¡åƒè€ƒå½±åƒ
        print("ğŸ“Š å°‡ç›´æ¥è™•ç†åŸå§‹ç…§ç‰‡ï¼Œç„¡å®šé‡è©•ä¼°æŒ‡æ¨™")
    
    # å„²å­˜çµæœå’Œè©•ä¼°æŒ‡æ¨™
    results = []
    
    print("\nğŸš€ é–‹å§‹æ‡‰ç”¨é€²éšå»å™ªæ–¹æ³•...")
    
    # 1. å°æ³¢å»å™ª
    print("ğŸ“Š è™•ç†å°æ³¢å»å™ª...")
    wavelet_filtered = wavelet_denoising(input_image, wavelet='db4', sigma=0.1)
    save_image(wavelet_filtered, os.path.join(output_dir, '02_wavelet_filtered.png'))
    if reference_image is not None:
        psnr_wavelet = calculate_psnr(reference_image, wavelet_filtered)
        ssim_wavelet = calculate_cw_ssim(reference_image, wavelet_filtered)
        results.append(("å°æ³¢å»å™ª", psnr_wavelet, ssim_wavelet))
    
    # 2. éå±€éƒ¨å‡å€¼å»å™ª
    print("ğŸ“Š è™•ç†éå±€éƒ¨å‡å€¼å»å™ª...")
    nlm_filtered = non_local_means_denoising(input_image, h=10, 
                                           templateWindowSize=7, 
                                           searchWindowSize=21)
    save_image(nlm_filtered, os.path.join(output_dir, '03_nlm_filtered.png'))
    if reference_image is not None:
        psnr_nlm = calculate_psnr(reference_image, nlm_filtered)
        ssim_nlm = calculate_cw_ssim(reference_image, nlm_filtered)
        results.append(("éå±€éƒ¨å‡å€¼", psnr_nlm, ssim_nlm))
    
    # 3. å…¨è®Šåˆ†å»å™ª
    print("ğŸ“Š è™•ç†å…¨è®Šåˆ†å»å™ª...")
    tv_filtered = total_variation_denoising(input_image, weight=0.1)
    save_image(tv_filtered, os.path.join(output_dir, '04_tv_filtered.png'))
    if reference_image is not None:
        psnr_tv = calculate_psnr(reference_image, tv_filtered)
        ssim_tv = calculate_cw_ssim(reference_image, tv_filtered)
        results.append(("å…¨è®Šåˆ†å»å™ª", psnr_tv, ssim_tv))
    
    # 4. è‡ªé©æ‡‰æ¿¾æ³¢å™¨
    print("ğŸ“Š è™•ç†è‡ªé©æ‡‰æ¿¾æ³¢å™¨...")
    adaptive_filtered = adaptive_filter_denoising(input_image, noise_var=900)
    save_image(adaptive_filtered, os.path.join(output_dir, '05_adaptive_filtered.png'))
    if reference_image is not None:
        psnr_adaptive = calculate_psnr(reference_image, adaptive_filtered)
        ssim_adaptive = calculate_cw_ssim(reference_image, adaptive_filtered)
        results.append(("è‡ªé©æ‡‰æ¿¾æ³¢å™¨", psnr_adaptive, ssim_adaptive))
    
    # 5. ç¨€ç–ç·¨ç¢¼å»å™ª
    print("ğŸ“Š è™•ç†ç¨€ç–ç·¨ç¢¼å»å™ª...")
    sparse_filtered = sparse_coding_denoising(input_image, n_components=100, 
                                            patch_size=8, alpha=1.0)
    save_image(sparse_filtered, os.path.join(output_dir, '06_sparse_filtered.png'))
    if reference_image is not None:
        psnr_sparse = calculate_psnr(reference_image, sparse_filtered)
        ssim_sparse = calculate_cw_ssim(reference_image, sparse_filtered)
        results.append(("ç¨€ç–ç·¨ç¢¼å»å™ª", psnr_sparse, ssim_sparse))
    
    # é¡¯ç¤ºçµæœ
    print("\nâœ¨ è™•ç†å®Œæˆï¼")
    
    if results:
        print("ğŸ“Š å®šé‡è©•ä¼°çµæœï¼š")
        print("=" * 70)
        print(f"{'æ–¹æ³•':<15} {'PSNR (dB)':<12} {'CW-SSIM':<12} {'ç¶œåˆè©•åˆ†':<12}")
        print("=" * 70)
        
        for method, psnr, ssim in results:
            # ç¶œåˆè©•åˆ† = 0.6 * PSNR/40 + 0.4 * SSIM
            combined_score = 0.6 * (psnr / 40) + 0.4 * ssim
            print(f"{method:<15} {psnr:<12.4f} {ssim:<12.6f} {combined_score:<12.6f}")
        
        print("=" * 70)
        
        # æ‰¾å‡ºæœ€ä½³æ–¹æ³•
        best_method_psnr = max(results, key=lambda x: x[1])
        best_method_ssim = max(results, key=lambda x: x[2])
        best_method_combined = max(results, key=lambda x: 0.6 * (x[1] / 40) + 0.4 * x[2])
        
        print(f"ğŸ† PSNR æœ€ä½³: {best_method_psnr[0]} ({best_method_psnr[1]:.4f} dB)")
        print(f"ğŸ† SSIM æœ€ä½³: {best_method_ssim[0]} ({best_method_ssim[2]:.6f})")
        print(f"ğŸ† ç¶œåˆæœ€ä½³: {best_method_combined[0]}")
    else:
        print("ğŸ’¡ å¯¦ç”¨æ¨¡å¼ï¼šè«‹æŸ¥çœ‹è¼¸å‡ºåœ–åƒä¾†æ¯”è¼ƒä¸åŒæ–¹æ³•çš„è¦–è¦ºæ•ˆæœ")
    
    print(f"\nğŸ“ æ‰€æœ‰çµæœå·²ä¿å­˜åˆ° '{output_dir}' è³‡æ–™å¤¾")
    print("ğŸ“¸ è¼¸å‡ºæª”æ¡ˆæ¸…å–®ï¼š")
    for i, filename in enumerate(sorted(os.listdir(output_dir))):
        if filename.endswith('.png'):
            print(f"  {i+1:2d}. {filename}")

if __name__ == "__main__":
    main() 